{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "desired_frames = 1\n",
    "desired_features = 1458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b3e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"scene_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17a8765",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>KEY</th>\n",
       "      <th>SPEAKER</th>\n",
       "      <th>SHOW</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Sarcasm_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_u</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_u</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>1_1001_u</td>\n",
       "      <td>RAJ</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1003</td>\n",
       "      <td>1_1003_u</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>BBT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_10190</td>\n",
       "      <td>1_10190_u</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SCENE        KEY  SPEAKER SHOW  Sarcasm Sarcasm_Type\n",
       "0  1_10004  1_10004_u  SHELDON  BBT      0.0         NONE\n",
       "1  1_10009  1_10009_u    PENNY  BBT      0.0         NONE\n",
       "2   1_1001   1_1001_u      RAJ  BBT      0.0         NONE\n",
       "3   1_1003   1_1003_u   HOWARD  BBT      1.0          PRO\n",
       "4  1_10190  1_10190_u  SHELDON  BBT      0.0         NONE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9904e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = list(pd.unique(labels[\"SCENE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88143cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41dd5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('audio_embed_final.pickle', 'rb')\n",
    "audio_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac3885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('text_embed_pca_final.pickle', 'rb')\n",
    "text_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6063d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_data = {}\n",
    "for scene in scenes:\n",
    "    at_data[scene] = np.concatenate((audio_data[scene], text_data[scene]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8dd9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 1458)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_data['1_10004'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6d81a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f80367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(at_features):\n",
    "    model_data = pd.DataFrame(columns=['at_feature','sarcasm','sarcasm_type', 'speaker'])\n",
    "    for index, row in labels.iterrows():\n",
    "        model_data = model_data.append({'at_feature': at_features[row[\"SCENE\"]],\n",
    "                                    'sarcasm' : row[\"Sarcasm\"],\n",
    "                                    'sarcasm_type' : row[\"Sarcasm_Type\"],\n",
    "                                    'speaker' : row[\"SPEAKER\"]},\n",
    "                                  ignore_index=True)\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c39e9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(model_data, x_columns, y_column, stratify_column):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        model_data[x_columns],\n",
    "        model_data[y_column],\n",
    "        train_size=0.8, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        shuffle=True,\n",
    "        stratify=model_data[stratify_column])\n",
    "    \n",
    "    print(\"Train: \",X_train.shape, Y_train.shape,\n",
    "      \"Test: \",(X_test.shape, Y_test.shape))\n",
    "    train_data = pd.merge(X_train, Y_train, left_index=True, right_index=True)\n",
    "    test_data = pd.merge(X_test, Y_test, left_index=True, right_index=True)\n",
    "    return train_data, test_data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d753e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTensorDataset(Dataset):\n",
    "    def __init__(self, dataframe, speaker):\n",
    "        self.data = dataframe\n",
    "        self.speaker = speaker\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.speaker:\n",
    "            features = self.data.loc[index, 'padded_at_feature']\n",
    "            a=np.empty((18,1))\n",
    "            a.fill(self.data.loc[index, 'speaker_encode'])\n",
    "            final_features = np.hstack((features, a))\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.from_numpy(final_features).float(), label\n",
    "        else:\n",
    "            features = self.data.loc[index, 'padded_at_feature']\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.from_numpy(features).float(), label\n",
    "    \n",
    "    def __getindexlist__(self):\n",
    "        return list(self.data.index.values)\n",
    "    \n",
    "class RNNetSD(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(RNNetSD, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = layers\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True, nonlinearity=\"relu\")\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = Variable(torch.zeros(self.layers, x.size(0), self.hidden_dim))\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = F.softmax(self.fc(out[:, -1, :]))\n",
    "        return out\n",
    "    \n",
    "class RNNetSID(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(RNNetSID, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = layers\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True, nonlinearity=\"relu\")\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = Variable(torch.zeros(self.layers, x.size(0), self.hidden_dim))\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = F.softmax(self.fc(out[:, -1, :]))\n",
    "        return out\n",
    "    \n",
    "def evaluateRNN(rnn, review, size):\n",
    "    output = rnn(review)\n",
    "    return output\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = torch.max(output,dim=1)\n",
    "    return top_i\n",
    "\n",
    "def test_accuracy(rnn, loader, size):\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    for data, target in loader:\n",
    "        output = evaluateRNN(rnn, data, size)\n",
    "        prediction_index = categoryFromOutput(output)\n",
    "        predictions = prediction_index.tolist()\n",
    "        actuals = target.tolist()\n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "508b145f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>at_feature</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sarcasm_type</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-637.1869506835938, 10.25528335571289, -3.98...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-625.8624267578125, 51.68547058105469, 40.30...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-500.3988952636719, 21.715717315673828, 18.9...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>RAJ</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-313.1777038574219, 97.45339965820312, -58.0...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PRO</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-337.88116455078125, 107.24081420898438, -49...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          at_feature  sarcasm sarcasm_type  \\\n",
       "0  [[-637.1869506835938, 10.25528335571289, -3.98...      0.0         NONE   \n",
       "1  [[-625.8624267578125, 51.68547058105469, 40.30...      0.0         NONE   \n",
       "2  [[-500.3988952636719, 21.715717315673828, 18.9...      0.0         NONE   \n",
       "3  [[-313.1777038574219, 97.45339965820312, -58.0...      1.0          PRO   \n",
       "4  [[-337.88116455078125, 107.24081420898438, -49...      0.0         NONE   \n",
       "\n",
       "   speaker  speaker_encode  \n",
       "0  SHELDON              25  \n",
       "1    PENNY              15  \n",
       "2      RAJ              21  \n",
       "3   HOWARD               7  \n",
       "4  SHELDON              25  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_data = get_model_data(at_data)\n",
    "# Label Encode Speaker\n",
    "le = preprocessing.LabelEncoder()\n",
    "model_data['speaker_encode'] = le.fit_transform(model_data['speaker'])\n",
    "model_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66053fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (961, 2) (961,) Test:  ((241, 2), (241,))\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_train_test_split(model_data, ['at_feature', 'speaker_encode'], 'sarcasm', 'sarcasm_type')\n",
    "rnn_train = train_data.copy()\n",
    "rnn_test = test_data.copy()\n",
    "rnn_train.reset_index(drop=True, inplace = True)\n",
    "rnn_test.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f6e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_length = 18\n",
    "\n",
    "rnn_train['padded_at_feature'] = rnn_train.loc[:, 'at_feature']\n",
    "rnn_test['padded_at_feature'] = rnn_test.loc[:, 'at_feature']\n",
    "\n",
    "rnn_train[\"sarcasm\"] = rnn_train[\"sarcasm\"].astype('int').to_numpy()\n",
    "rnn_test[\"sarcasm\"] = rnn_test[\"sarcasm\"].astype('int').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41fb73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM_sid = 1458\n",
    "EMBEDDING_DIM_sd = 1459\n",
    "HIDDEN_DIM = 20\n",
    "OUTPUT_DIM = 2\n",
    "layers = 2\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879089b1",
   "metadata": {},
   "source": [
    "### Speaker Dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f972827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train_tensor = RNNTensorDataset(rnn_train[['padded_at_feature', 'speaker_encode','sarcasm']], True)\n",
    "rnn_test_tensor = RNNTensorDataset(rnn_test[['padded_at_feature', 'speaker_encode', 'sarcasm']], True)\n",
    "\n",
    "num_of_workers = 0\n",
    "batch_size = 44\n",
    "valid_size = 0.1\n",
    "\n",
    "train_indices = list(range(len(rnn_train_tensor)))\n",
    "np.random.shuffle(train_indices)\n",
    "\n",
    "test_indices = list(range(len(rnn_test_tensor)))\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    rnn_train_tensor, \n",
    "    batch_size=batch_size, \n",
    "    sampler=SubsetRandomSampler(train_indices)\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    rnn_test_tensor, \n",
    "    batch_size=batch_size, \n",
    "    sampler=SubsetRandomSampler(test_indices)\n",
    ")\n",
    "\n",
    "test_loader_epoch = torch.utils.data.DataLoader(\n",
    "    rnn_test_tensor, batch_size=rnn_test_tensor.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c36ed74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNetSD(\n",
      "  (rnn): RNN(1459, 20, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNNetSD(EMBEDDING_DIM_sd, HIDDEN_DIM, OUTPUT_DIM, layers)\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d915c1f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5021    0.9833    0.6648       120\n",
      "           1     0.6667    0.0331    0.0630       121\n",
      "\n",
      "    accuracy                         0.5062       241\n",
      "   macro avg     0.5844    0.5082    0.3639       241\n",
      "weighted avg     0.5847    0.5062    0.3626       241\n",
      "\n",
      "Epoch: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6131    0.7000    0.6537       120\n",
      "           1     0.6538    0.5620    0.6044       121\n",
      "\n",
      "    accuracy                         0.6307       241\n",
      "   macro avg     0.6335    0.6310    0.6291       241\n",
      "weighted avg     0.6336    0.6307    0.6290       241\n",
      "\n",
      "Epoch: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5800    0.7250    0.6444       120\n",
      "           1     0.6374    0.4793    0.5472       121\n",
      "\n",
      "    accuracy                         0.6017       241\n",
      "   macro avg     0.6087    0.6022    0.5958       241\n",
      "weighted avg     0.6088    0.6017    0.5956       241\n",
      "\n",
      "Epoch: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5691    0.5833    0.5761       120\n",
      "           1     0.5763    0.5620    0.5690       121\n",
      "\n",
      "    accuracy                         0.5726       241\n",
      "   macro avg     0.5727    0.5727    0.5726       241\n",
      "weighted avg     0.5727    0.5726    0.5726       241\n",
      "\n",
      "Epoch: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5606    0.6167    0.5873       120\n",
      "           1     0.5780    0.5207    0.5478       121\n",
      "\n",
      "    accuracy                         0.5685       241\n",
      "   macro avg     0.5693    0.5687    0.5676       241\n",
      "weighted avg     0.5693    0.5685    0.5675       241\n",
      "\n",
      "Epoch: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5840    0.6083    0.5959       120\n",
      "           1     0.5948    0.5702    0.5823       121\n",
      "\n",
      "    accuracy                         0.5892       241\n",
      "   macro avg     0.5894    0.5893    0.5891       241\n",
      "weighted avg     0.5894    0.5892    0.5891       241\n",
      "\n",
      "Epoch: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5606    0.6167    0.5873       120\n",
      "           1     0.5780    0.5207    0.5478       121\n",
      "\n",
      "    accuracy                         0.5685       241\n",
      "   macro avg     0.5693    0.5687    0.5676       241\n",
      "weighted avg     0.5693    0.5685    0.5675       241\n",
      "\n",
      "Epoch: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5606    0.6167    0.5873       120\n",
      "           1     0.5780    0.5207    0.5478       121\n",
      "\n",
      "    accuracy                         0.5685       241\n",
      "   macro avg     0.5693    0.5687    0.5676       241\n",
      "weighted avg     0.5693    0.5685    0.5675       241\n",
      "\n",
      "Epoch: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5573    0.6083    0.5817       120\n",
      "           1     0.5727    0.5207    0.5455       121\n",
      "\n",
      "    accuracy                         0.5643       241\n",
      "   macro avg     0.5650    0.5645    0.5636       241\n",
      "weighted avg     0.5650    0.5643    0.5635       241\n",
      "\n",
      "Epoch: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5573    0.6083    0.5817       120\n",
      "           1     0.5727    0.5207    0.5455       121\n",
      "\n",
      "    accuracy                         0.5643       241\n",
      "   macro avg     0.5650    0.5645    0.5636       241\n",
      "weighted avg     0.5650    0.5643    0.5635       241\n",
      "\n",
      "Epoch: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5573    0.6083    0.5817       120\n",
      "           1     0.5727    0.5207    0.5455       121\n",
      "\n",
      "    accuracy                         0.5643       241\n",
      "   macro avg     0.5650    0.5645    0.5636       241\n",
      "weighted avg     0.5650    0.5643    0.5635       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 101\n",
    "    \n",
    "test_min_loss = np.inf\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    torch.manual_seed(42)\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    rnn.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = rnn(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    rnn.eval()\n",
    "    for data, target in test_loader:\n",
    "        if data.shape[1] < 44:\n",
    "            continue\n",
    "        output = rnn(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    if(epoch%10 == 0):\n",
    "        print(\"Epoch: \" + str(epoch))\n",
    "        predictions, actuals = test_accuracy(rnn, test_loader_epoch, rnn_test_tensor.__len__())\n",
    "        print(classification_report(actuals, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40627ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f15942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70565651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
