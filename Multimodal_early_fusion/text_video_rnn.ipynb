{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "desired_frames = 1\n",
    "desired_features = 2816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b3e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/data/scene_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17a8765",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>KEY</th>\n",
       "      <th>SPEAKER</th>\n",
       "      <th>SHOW</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Sarcasm_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_u</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_u</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>1_1001_u</td>\n",
       "      <td>RAJ</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1003</td>\n",
       "      <td>1_1003_u</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>BBT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_10190</td>\n",
       "      <td>1_10190_u</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SCENE        KEY  SPEAKER SHOW  Sarcasm Sarcasm_Type\n",
       "0  1_10004  1_10004_u  SHELDON  BBT      0.0         NONE\n",
       "1  1_10009  1_10009_u    PENNY  BBT      0.0         NONE\n",
       "2   1_1001   1_1001_u      RAJ  BBT      0.0         NONE\n",
       "3   1_1003   1_1003_u   HOWARD  BBT      1.0          PRO\n",
       "4  1_10190  1_10190_u  SHELDON  BBT      0.0         NONE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9904e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = list(pd.unique(labels[\"SCENE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88143cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67bf3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/MultiModal/Early Fusion/Data/text_embed_pca_final.pickle', 'rb')\n",
    "text_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde91a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/MultiModal/Early Fusion/Data/visual_embed_padded_final.pickle', 'rb')\n",
    "video_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c283c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_data = {}\n",
    "for scene in scenes:\n",
    "    tv_data[scene] = np.concatenate((text_data[scene], video_data[scene]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb6b1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 2816)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_data['1_10004'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f80367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(tv_data):\n",
    "    model_data = pd.DataFrame(columns=['tv_feature','sarcasm','sarcasm_type', 'speaker'])\n",
    "    for index, row in labels.iterrows():\n",
    "#         audio_key = row[\"SCENE\"] + \"_u.wav\"\n",
    "        model_data = model_data.append({'tv_feature': tv_data[row['SCENE']], \n",
    "                                    'sarcasm' : row[\"Sarcasm\"],\n",
    "                                    'sarcasm_type' : row[\"Sarcasm_Type\"],\n",
    "                                    'speaker' : row[\"SPEAKER\"]},\n",
    "                                  ignore_index=True)\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c39e9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(model_data, x_columns, y_column, stratify_column):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        model_data[x_columns],\n",
    "        model_data[y_column],\n",
    "        train_size=0.8, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        shuffle=True,\n",
    "        stratify=model_data[stratify_column])\n",
    "    \n",
    "    print(\"Train: \",X_train.shape, Y_train.shape,\n",
    "      \"Test: \",(X_test.shape, Y_test.shape))\n",
    "    train_data = pd.merge(X_train, Y_train, left_index=True, right_index=True)\n",
    "    test_data = pd.merge(X_test, Y_test, left_index=True, right_index=True)\n",
    "    return train_data, test_data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d753e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTensorDataset(Dataset):\n",
    "    def __init__(self, dataframe, speaker):\n",
    "        self.data = dataframe\n",
    "        self.speaker = speaker\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.speaker:\n",
    "            features = self.data.loc[index, 'padded_tv_feature']\n",
    "            a=np.empty((18,1))\n",
    "            a.fill(self.data.loc[index, 'speaker_encode'])\n",
    "            final_features = np.hstack((features, a))\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.from_numpy(final_features).float(), label\n",
    "        else:\n",
    "            features = self.data.loc[index, 'padded_tv_feature']\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.from_numpy(features).float(), label\n",
    "    \n",
    "    def __getindexlist__(self):\n",
    "        return list(self.data.index.values)\n",
    "    \n",
    "class RNNetSD(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(RNNetSD, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = layers\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True, nonlinearity=\"relu\")\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = Variable(torch.zeros(self.layers, x.size(0), self.hidden_dim))\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = F.softmax(self.fc(out[:, -1, :]))\n",
    "        return out\n",
    "    \n",
    "class RNNetSID(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(RNNetSID, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = layers\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True, nonlinearity=\"relu\")\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = Variable(torch.zeros(self.layers, x.size(0), self.hidden_dim))\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = F.softmax(self.fc(out[:, -1, :]))\n",
    "        return out\n",
    "    \n",
    "def evaluateRNN(rnn, review, size):\n",
    "    output = rnn(review)\n",
    "    return output\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = torch.max(output,dim=1)\n",
    "    return top_i\n",
    "\n",
    "def test_accuracy(rnn, loader, size):\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    for data, target in loader:\n",
    "        output = evaluateRNN(rnn, data, size)\n",
    "        prediction_index = categoryFromOutput(output)\n",
    "        predictions = prediction_index.tolist()\n",
    "        actuals = target.tolist()\n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "508b145f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv_feature</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sarcasm_type</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-5.775393, -0.55747294, -5.9735856, 0.882094...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-9.726368, -4.6866755, -11.944455, -6.425826...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-14.0798025, 4.135473, -8.056498, -4.865928,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>RAJ</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-5.3839507, 2.0448134, -13.128815, -6.819113...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PRO</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-3.3831522, 5.3072224, -5.980673, -1.8846271...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tv_feature  sarcasm sarcasm_type  \\\n",
       "0  [[-5.775393, -0.55747294, -5.9735856, 0.882094...      0.0         NONE   \n",
       "1  [[-9.726368, -4.6866755, -11.944455, -6.425826...      0.0         NONE   \n",
       "2  [[-14.0798025, 4.135473, -8.056498, -4.865928,...      0.0         NONE   \n",
       "3  [[-5.3839507, 2.0448134, -13.128815, -6.819113...      1.0          PRO   \n",
       "4  [[-3.3831522, 5.3072224, -5.980673, -1.8846271...      0.0         NONE   \n",
       "\n",
       "   speaker  speaker_encode  \n",
       "0  SHELDON              25  \n",
       "1    PENNY              15  \n",
       "2      RAJ              21  \n",
       "3   HOWARD               7  \n",
       "4  SHELDON              25  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_data = get_model_data(tv_data)\n",
    "# Label Encode Speaker\n",
    "le = preprocessing.LabelEncoder()\n",
    "model_data['speaker_encode'] = le.fit_transform(model_data['speaker'])\n",
    "model_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66053fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (961, 2) (961,) Test:  ((241, 2), (241,))\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_train_test_split(model_data, ['tv_feature', 'speaker_encode'], 'sarcasm', 'sarcasm_type')\n",
    "rnn_train = train_data.copy()\n",
    "rnn_test = test_data.copy()\n",
    "rnn_train.reset_index(drop=True, inplace = True)\n",
    "rnn_test.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f6e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_length = 18\n",
    "\n",
    "rnn_train['padded_tv_feature'] = rnn_train.loc[:, 'tv_feature']\n",
    "rnn_test['padded_tv_feature'] = rnn_test.loc[:, 'tv_feature']\n",
    "\n",
    "rnn_train[\"sarcasm\"] = rnn_train[\"sarcasm\"].astype('int').to_numpy()\n",
    "rnn_test[\"sarcasm\"] = rnn_test[\"sarcasm\"].astype('int').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41fb73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM_sid = 2816\n",
    "EMBEDDING_DIM_sd = 2817\n",
    "HIDDEN_DIM = 20\n",
    "OUTPUT_DIM = 2\n",
    "layers = 2\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879089b1",
   "metadata": {},
   "source": [
    "### Speaker Dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f972827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train_tensor = RNNTensorDataset(rnn_train[['padded_tv_feature', 'speaker_encode','sarcasm']], True)\n",
    "rnn_test_tensor = RNNTensorDataset(rnn_test[['padded_tv_feature', 'speaker_encode', 'sarcasm']], True)\n",
    "\n",
    "num_of_workers = 0\n",
    "batch_size = 44\n",
    "valid_size = 0.1\n",
    "\n",
    "train_indices = list(range(len(rnn_train_tensor)))\n",
    "np.random.shuffle(train_indices)\n",
    "\n",
    "test_indices = list(range(len(rnn_test_tensor)))\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    rnn_train_tensor, \n",
    "    batch_size=batch_size, \n",
    "    sampler=SubsetRandomSampler(train_indices)\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    rnn_test_tensor, \n",
    "    batch_size=batch_size, \n",
    "    sampler=SubsetRandomSampler(test_indices)\n",
    ")\n",
    "\n",
    "test_loader_epoch = torch.utils.data.DataLoader(\n",
    "    rnn_test_tensor, batch_size=rnn_test_tensor.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c36ed74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNetSD(\n",
      "  (rnn): RNN(2817, 20, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNNetSD(EMBEDDING_DIM_sd, HIDDEN_DIM, OUTPUT_DIM, layers)\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d915c1f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4752    0.5583    0.5134       120\n",
      "           1     0.4700    0.3884    0.4253       121\n",
      "\n",
      "    accuracy                         0.4730       241\n",
      "   macro avg     0.4726    0.4734    0.4694       241\n",
      "weighted avg     0.4726    0.4730    0.4692       241\n",
      "\n",
      "Epoch: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5352    0.6333    0.5802       120\n",
      "           1     0.5556    0.4545    0.5000       121\n",
      "\n",
      "    accuracy                         0.5436       241\n",
      "   macro avg     0.5454    0.5439    0.5401       241\n",
      "weighted avg     0.5454    0.5436    0.5399       241\n",
      "\n",
      "Epoch: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5259    0.5917    0.5569       120\n",
      "           1     0.5377    0.4711    0.5022       121\n",
      "\n",
      "    accuracy                         0.5311       241\n",
      "   macro avg     0.5318    0.5314    0.5295       241\n",
      "weighted avg     0.5319    0.5311    0.5294       241\n",
      "\n",
      "Epoch: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5294    0.6000    0.5625       120\n",
      "           1     0.5429    0.4711    0.5044       121\n",
      "\n",
      "    accuracy                         0.5353       241\n",
      "   macro avg     0.5361    0.5355    0.5335       241\n",
      "weighted avg     0.5362    0.5353    0.5333       241\n",
      "\n",
      "Epoch: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5448    0.6083    0.5748       120\n",
      "           1     0.5607    0.4959    0.5263       121\n",
      "\n",
      "    accuracy                         0.5519       241\n",
      "   macro avg     0.5528    0.5521    0.5506       241\n",
      "weighted avg     0.5528    0.5519    0.5505       241\n",
      "\n",
      "Epoch: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5407    0.6083    0.5725       120\n",
      "           1     0.5566    0.4876    0.5198       121\n",
      "\n",
      "    accuracy                         0.5477       241\n",
      "   macro avg     0.5487    0.5480    0.5462       241\n",
      "weighted avg     0.5487    0.5477    0.5461       241\n",
      "\n",
      "Epoch: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5407    0.6083    0.5725       120\n",
      "           1     0.5566    0.4876    0.5198       121\n",
      "\n",
      "    accuracy                         0.5477       241\n",
      "   macro avg     0.5487    0.5480    0.5462       241\n",
      "weighted avg     0.5487    0.5477    0.5461       241\n",
      "\n",
      "Epoch: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5407    0.6083    0.5725       120\n",
      "           1     0.5566    0.4876    0.5198       121\n",
      "\n",
      "    accuracy                         0.5477       241\n",
      "   macro avg     0.5487    0.5480    0.5462       241\n",
      "weighted avg     0.5487    0.5477    0.5461       241\n",
      "\n",
      "Epoch: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5407    0.6083    0.5725       120\n",
      "           1     0.5566    0.4876    0.5198       121\n",
      "\n",
      "    accuracy                         0.5477       241\n",
      "   macro avg     0.5487    0.5480    0.5462       241\n",
      "weighted avg     0.5487    0.5477    0.5461       241\n",
      "\n",
      "Epoch: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5414    0.6000    0.5692       120\n",
      "           1     0.5556    0.4959    0.5240       121\n",
      "\n",
      "    accuracy                         0.5477       241\n",
      "   macro avg     0.5485    0.5479    0.5466       241\n",
      "weighted avg     0.5485    0.5477    0.5465       241\n",
      "\n",
      "Epoch: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5489    0.6083    0.5771       120\n",
      "           1     0.5648    0.5041    0.5328       121\n",
      "\n",
      "    accuracy                         0.5560       241\n",
      "   macro avg     0.5568    0.5562    0.5549       241\n",
      "weighted avg     0.5569    0.5560    0.5548       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 101\n",
    "    \n",
    "test_min_loss = np.inf\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    torch.manual_seed(42)\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    rnn.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = rnn(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    rnn.eval()\n",
    "    for data, target in test_loader:\n",
    "        if data.shape[1] < 44:\n",
    "            continue\n",
    "        output = rnn(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    if(epoch%10 == 0):\n",
    "        print(\"Epoch: \" + str(epoch))\n",
    "        predictions, actuals = test_accuracy(rnn, test_loader_epoch, rnn_test_tensor.__len__())\n",
    "        print(classification_report(actuals, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40627ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f15942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70565651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
