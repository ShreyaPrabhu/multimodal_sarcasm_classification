{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1317046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import Audio\n",
    "import soundfile as sf\n",
    "import os\n",
    "import ffmpy\n",
    "import warnings\n",
    "import opensmile\n",
    "import csv\n",
    "import pandas as pd \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "AUDIOS_FOLDER = \"../data/audios/final_utterance_videos\"\n",
    "CONTEXT_AUDIOS_FOLDER = \"../data/audios/final_context_videos\"\n",
    "AUDIOS_FOLDER_WAV = \"../data/audios/final_utterance_videos_wav\"\n",
    "AUDIOS_FOLDER__BGR_WAV = \"../data/audios/final_utterance_videos_bgr_wav\"\n",
    "CONTEXT_AUDIOS_FOLDER_WAV = \"../data/audios/final_context_videos_wav\"\n",
    "CONTEXT_AUDIOS_FOLDER__BGR_WAV = \"../data/audios/final_context_videos_bgr_wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e312c",
   "metadata": {},
   "source": [
    "## Convert mp4 to wav file and remove background noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a32469a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(AUDIOS_FOLDER):\n",
    "    actual_filename = filename.rsplit(\".\", maxsplit=1)[0]\n",
    "    if(filename.endswith(\".mp4\")):\n",
    "        os.system('ffmpeg -i {} -acodec pcm_s16le {}.wav'.format(\n",
    "            os.path.join(AUDIOS_FOLDER, filename), os.path.join(AUDIOS_FOLDER_WAV, actual_filename)))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c9ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(CONTEXT_AUDIOS_FOLDER):\n",
    "    actual_filename = filename.rsplit(\".\", maxsplit=1)[0]\n",
    "    if(filename.endswith(\".mp4\")):\n",
    "        os.system('ffmpeg -i {} -acodec pcm_s16le {}.wav'.format(\n",
    "            os.path.join(CONTEXT_AUDIOS_FOLDER, filename), os.path.join(CONTEXT_AUDIOS_FOLDER_WAV, actual_filename)))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9276f",
   "metadata": {},
   "source": [
    "## Librosa\n",
    "\n",
    "Usually background noises are removed using frequency of foreground and background noise. This doesn't work in our case as the waveshow below shows that dialogue and background laughter have similar frequencies. We can sample foreground audio data to an extent using librosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c5098a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_dict = {}\n",
    "src_dir = AUDIOS_FOLDER_WAV\n",
    "hop_length = 512\n",
    "\n",
    "for f in os.listdir(src_dir):\n",
    "    if f.endswith(\".wav\"):\n",
    "        y, sr = librosa.load(os.path.join(src_dir, f))\n",
    "        D = librosa.stft(y, hop_length=hop_length)\n",
    "        S_full, phase = librosa.magphase(D)\n",
    "        S_filter = librosa.decompose.nn_filter(S_full, aggregate=np.median, metric=\"cosine\")\n",
    "        S_filter = np.minimum(S_full, S_filter)\n",
    "        margin_i, margin_v = 2, 4\n",
    "        power = 2\n",
    "        mask_v = librosa.util.softmask(S_full - S_filter, margin_v * S_filter, power=power)\n",
    "        S_foreground = mask_v * S_full\n",
    "        new_D = S_foreground * phase\n",
    "        y_foreground = librosa.istft(new_D)\n",
    "        sf.write(os.path.join(AUDIOS_FOLDER__BGR_WAV, f), y_foreground, sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y_foreground, sr=sr, n_mfcc=13)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        rms = librosa.feature.rms(y=y_foreground, hop_length=hop_length)\n",
    "        rms_delta = librosa.feature.delta(rms)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=y_foreground)\n",
    "        zcr_delta = librosa.feature.delta(zcr)\n",
    "        tone = librosa.feature.tonnetz(y=y_foreground, sr=sr)\n",
    "        tempogram = librosa.feature.tempogram(y=y_foreground, sr=sr)\n",
    "        tempogram_ratio = librosa.feature.tempogram_ratio(y=y_foreground, sr=sr)\n",
    "        S = librosa.feature.melspectrogram(y=y_foreground, sr=sr, n_mels=128, fmax=8000)\n",
    "        S_delta = librosa.feature.delta(S)\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=y_foreground, sr=sr, S=S_full)\n",
    "        \n",
    "        audio_feature = np.vstack((mfcc, mfcc_delta, rms, rms_delta, zcr, zcr_delta, tone, \n",
    "                                   tempogram, tempogram_ratio, S, S_delta, spectral_centroid))\n",
    "        jump = int(audio_feature.shape[1] / 10)\n",
    "        feat_data = librosa.util.sync(audio_feature, range(1, audio_feature.shape[1], jump))\n",
    "        feat_dict[f] = feat_data\n",
    "\n",
    "\n",
    "with open('feat_dict_librosa_lld.pickle', 'wb') as handle:\n",
    "    pickle.dump(feat_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06361e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = {}\n",
    "src_dir = CONTEXT_AUDIOS_FOLDER_WAV\n",
    "hop_length = 512\n",
    "\n",
    "for f in os.listdir(src_dir):\n",
    "    if f.endswith(\".wav\"):\n",
    "        y, sr = librosa.load(os.path.join(src_dir, f))\n",
    "        D = librosa.stft(y, hop_length=hop_length)\n",
    "        S_full, phase = librosa.magphase(D)\n",
    "        S_filter = librosa.decompose.nn_filter(S_full, aggregate=np.median, metric=\"cosine\")\n",
    "        S_filter = np.minimum(S_full, S_filter)\n",
    "        margin_i, margin_v = 2, 4\n",
    "        power = 2\n",
    "        mask_v = librosa.util.softmask(S_full - S_filter, margin_v * S_filter, power=power)\n",
    "        S_foreground = mask_v * S_full\n",
    "        new_D = S_foreground * phase\n",
    "        y_foreground = librosa.istft(new_D)\n",
    "        sf.write(os.path.join(CONTEXT_AUDIOS_FOLDER__BGR_WAV, f), y_foreground, sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y_foreground, sr=sr, n_mfcc=13)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        rms = librosa.feature.rms(y=y_foreground, hop_length=hop_length)\n",
    "        rms_delta = librosa.feature.delta(rms)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=y_foreground)\n",
    "        zcr_delta = librosa.feature.delta(zcr)\n",
    "        tone = librosa.feature.tonnetz(y=y_foreground, sr=sr)\n",
    "        tempogram = librosa.feature.tempogram(y=y_foreground, sr=sr)\n",
    "        tempogram_ratio = librosa.feature.tempogram_ratio(y=y_foreground, sr=sr)\n",
    "        S = librosa.feature.melspectrogram(y=y_foreground, sr=sr, n_mels=128, fmax=8000)\n",
    "        S_delta = librosa.feature.delta(S)\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=y_foreground, sr=sr, S=S_full)\n",
    "        \n",
    "        audio_feature = np.vstack((mfcc, mfcc_delta, rms, rms_delta, zcr, zcr_delta, tone, \n",
    "                                   tempogram, tempogram_ratio, S, S_delta, spectral_centroid))\n",
    "        jump = int(audio_feature.shape[1] / 10)\n",
    "        feat_data = librosa.util.sync(audio_feature, range(1, audio_feature.shape[1], jump))\n",
    "        feat_dict[f] = feat_data\n",
    "\n",
    "\n",
    "with open('feat_dict_context_librosa_lld.pickle', 'wb') as handle:\n",
    "    pickle.dump(feat_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1152e18",
   "metadata": {},
   "source": [
    "## OpenSmile \n",
    "Prosody features extraction \n",
    "\n",
    "OpenSmile shell script is processing only 493 wave files. Rest threw \"Maybe this is not a WAVE file?\" <br>\n",
    "OpenSmile python is working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e8e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = {}\n",
    "\n",
    "smile_lld = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.LowLevelDescriptors,\n",
    ")\n",
    "\n",
    "# # captured on whole for each video\n",
    "# smile_predefined = opensmile.Smile(\n",
    "#     feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "#     feature_level=opensmile.FeatureLevel.Functionals,\n",
    "# )\n",
    "#+smile_predefined.feature_names\n",
    "#     spredefined = smile_predefined.process_file(os.path.join(src_dir,f))\n",
    "#     df_concat = pd.concat([slld, spredefined], axis=1)\n",
    "\n",
    "df = pd.DataFrame(columns=smile_lld.feature_names)\n",
    "\n",
    "\n",
    "src_dir = AUDIOS_FOLDER__BGR_WAV\n",
    "for f in os.listdir(src_dir):\n",
    "    if f.endswith(\".wav\"):\n",
    "        spd = smile_lld.process_file(os.path.join(src_dir,f))\n",
    "        feat_dict[f] = np.transpose(spd.to_numpy())\n",
    "        df = df.append(spd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd0eef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"framewise_feat_opensmile_lld.csv\")\n",
    "with open('feat_dict_opensmile_lld.pickle', 'wb') as handle:\n",
    "    pickle.dump(feat_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9163d0e",
   "metadata": {},
   "source": [
    "### Frame config changes to align librosa and opensmile features\n",
    "Check if we can merge opensmile and librosa features.  <br>\n",
    "Try frame parameters for opensmile - https://github.com/audeering/opensmile-python/issues/14 <br>\n",
    "\n",
    "Tried - <br>\n",
    "https://github.com/audeering/opensmile-python/issues/76 <br>\n",
    "https://github.com/audeering/opensmile-python/issues/57 <br>\n",
    "Configs updated to have frame size of 93ms and frame step of 25ms based on Librosa paper https://conference.scipy.org/proceedings/scipy2015/pdfs/brian_mcfee.pdf <br>\n",
    "Package path local for config changes - /Users/shreyaprabhu/opt/miniconda3/lib/python3.9/site-packages/opensmile <br>\n",
    "\n",
    "### References \n",
    "https://github.com/soujanyaporia/MUStARD <br>\n",
    "https://audeering.github.io/opensmile-python/usage.html <br>\n",
    "https://github.com/ekayen/prosody_detection <br>\n",
    "\n",
    "Other methods/libraries tried - \n",
    "1. SOX for converting mp4 to wav file. SOX does not have handler for mp4 as of now. https://github.com/jacksonh/sox.\n",
    "2. Disvoice for prosody feature extraction. Did not work. Had package issues.\n",
    "3. Myprosody library for prosody feature extraction. The code is in initial stages and has hardcoded file paths. Did not work. https://github.com/Shahabks/myprosody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ca0b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shreyaprabhu/opt/miniconda3/lib/python3.9/site-packages/opensmile'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(opensmile.__file__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
