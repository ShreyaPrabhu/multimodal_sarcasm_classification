{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42e3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3da61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(X_train, X_test, Y_train, Y_test):\n",
    "    svm_clf = svm.SVC(random_state=0, kernel = \"rbf\", gamma = \"scale\", class_weight = \"balanced\")\n",
    "    C = C = [0.0001, 0.0003, 0.0005, 0.001, 0.003, 0.005, 0.01, 0.03, 0.05, 0.1, 0.3, 0.5, 1, 3, 5, 10]\n",
    "    gscv_clf = GridSearchCV(\n",
    "        estimator=svm_clf, \n",
    "        param_grid=dict(C=C),\n",
    "        n_jobs=-1, \n",
    "        cv = 10, \n",
    "        scoring = 'f1_weighted', \n",
    "        refit = True)\n",
    "\n",
    "    gscv_clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = gscv_clf.predict(X_test)\n",
    "    report = classification_report(Y_test, Y_test_pred, digits=4)\n",
    "    return report, gscv_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a94847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"../../text_features/bert_embeddings/train_labels.csv\")\n",
    "y_test = pd.read_csv(\"../../text_features/bert_embeddings/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386872bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../text_features/bert_embeddings/train_bert_embeddings_target_.pkl', 'rb') as f:\n",
    "    x_train = pickle.load(f, encoding='latin1')\n",
    "\n",
    "with open('../../text_features/bert_embeddings/test_bert_embeddings_target_.pkl', 'rb') as f:\n",
    "    x_test = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e07749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vals = []\n",
    "for sample in x_train[\"embeddings\"]:\n",
    "    x_train_vals.append(sample[0].tolist())\n",
    "    \n",
    "x_test_vals = []\n",
    "for sample in x_test[\"embeddings\"]:\n",
    "    x_test_vals.append(sample[0].tolist())\n",
    "\n",
    "x_train_df = pd.DataFrame({'embeddings':x_train_vals})\n",
    "x_test_df = pd.DataFrame({'embeddings':x_test_vals})\n",
    "\n",
    "def process_dataframes(data):\n",
    "    temp_concat = pd.concat([data, data.embeddings.apply(pd.Series)], axis=1)\n",
    "    temp_concat.drop(columns=['embeddings'], inplace = True)\n",
    "    return temp_concat.add_prefix('feat_')\n",
    "\n",
    "x_train_df = process_dataframes(x_train_df)\n",
    "x_test_df = process_dataframes(x_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d92cc",
   "metadata": {},
   "source": [
    "### Speaker Independent and Context Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a887b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report, best_est = svm_classifier(x_train_df, x_test_df, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709f8378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, class_weight=&#x27;balanced&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8058be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6789    0.6116    0.6435       121\n",
      "         1.0     0.6439    0.7083    0.6746       120\n",
      "\n",
      "    accuracy                         0.6598       241\n",
      "   macro avg     0.6614    0.6600    0.6590       241\n",
      "weighted avg     0.6615    0.6598    0.6590       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa6494",
   "metadata": {},
   "source": [
    "### Speaker Dependent and Context Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47110585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_</th>\n",
       "      <th>target_context</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] I've been told it's a good way to move o...</td>\n",
       "      <td>[CLS] I've been told it's a good way to move o...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] Yeah, sure. You slept with your husband....</td>\n",
       "      <td>[CLS] Yeah, sure. You slept with your husband....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] When are you coming home? [SEP]</td>\n",
       "      <td>[CLS] When are you coming home? Okay. Alright....</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] Riveting. [SEP]</td>\n",
       "      <td>[CLS] Riveting. Bingo. Then I lifted the cushi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] No, this is just part of a daredevil gam...</td>\n",
       "      <td>[CLS] No, this is just part of a daredevil gam...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>[CLS] Oh, that's sweet, but today is all about...</td>\n",
       "      <td>[CLS] Oh, that's sweet, but today is all about...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>[CLS] If you wanna put a label on it. [SEP]</td>\n",
       "      <td>[CLS] If you wanna put a label on it. You mean...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>[CLS] That you're an alcoholic? [SEP]</td>\n",
       "      <td>[CLS] That you're an alcoholic? I realized som...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>[CLS] All I see is a yellow smudge. [SEP]</td>\n",
       "      <td>[CLS] All I see is a yellow smudge. Now go bac...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>[CLS] I mean if you hadn't initiated it I-I-I ...</td>\n",
       "      <td>[CLS] I mean if you hadn't initiated it I-I-I ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               target_  \\\n",
       "0    [CLS] I've been told it's a good way to move o...   \n",
       "1    [CLS] Yeah, sure. You slept with your husband....   \n",
       "2                [CLS] When are you coming home? [SEP]   \n",
       "3                                [CLS] Riveting. [SEP]   \n",
       "4    [CLS] No, this is just part of a daredevil gam...   \n",
       "..                                                 ...   \n",
       "956  [CLS] Oh, that's sweet, but today is all about...   \n",
       "957        [CLS] If you wanna put a label on it. [SEP]   \n",
       "958              [CLS] That you're an alcoholic? [SEP]   \n",
       "959          [CLS] All I see is a yellow smudge. [SEP]   \n",
       "960  [CLS] I mean if you hadn't initiated it I-I-I ...   \n",
       "\n",
       "                                        target_context  speaker  \n",
       "0    [CLS] I've been told it's a good way to move o...       25  \n",
       "1    [CLS] Yeah, sure. You slept with your husband....        1  \n",
       "2    [CLS] When are you coming home? Okay. Alright....       16  \n",
       "3    [CLS] Riveting. Bingo. Then I lifted the cushi...        0  \n",
       "4    [CLS] No, this is just part of a daredevil gam...        2  \n",
       "..                                                 ...      ...  \n",
       "956  [CLS] Oh, that's sweet, but today is all about...        7  \n",
       "957  [CLS] If you wanna put a label on it. You mean...       24  \n",
       "958  [CLS] That you're an alcoholic? I realized som...        3  \n",
       "959  [CLS] All I see is a yellow smudge. Now go bac...       15  \n",
       "960  [CLS] I mean if you hadn't initiated it I-I-I ...       24  \n",
       "\n",
       "[961 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_speakers = pd.read_csv(\"../../text_features/bert_embeddings/train_data.csv\")\n",
    "x_test_speakers = pd.read_csv(\"../../text_features/bert_embeddings/test_data.csv\")\n",
    "x_train_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e76e6fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_759</th>\n",
       "      <th>feat_760</th>\n",
       "      <th>feat_761</th>\n",
       "      <th>feat_762</th>\n",
       "      <th>feat_763</th>\n",
       "      <th>feat_764</th>\n",
       "      <th>feat_765</th>\n",
       "      <th>feat_766</th>\n",
       "      <th>feat_767</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531574</td>\n",
       "      <td>-0.002677</td>\n",
       "      <td>-0.377449</td>\n",
       "      <td>-0.346509</td>\n",
       "      <td>-0.357004</td>\n",
       "      <td>-0.114968</td>\n",
       "      <td>-0.139359</td>\n",
       "      <td>0.510641</td>\n",
       "      <td>0.438597</td>\n",
       "      <td>-0.468832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395492</td>\n",
       "      <td>-0.281222</td>\n",
       "      <td>-0.151269</td>\n",
       "      <td>0.183464</td>\n",
       "      <td>-0.227712</td>\n",
       "      <td>0.016151</td>\n",
       "      <td>-0.106852</td>\n",
       "      <td>-0.075954</td>\n",
       "      <td>0.546363</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.230405</td>\n",
       "      <td>-0.500298</td>\n",
       "      <td>-0.502653</td>\n",
       "      <td>-0.045785</td>\n",
       "      <td>-0.408853</td>\n",
       "      <td>-0.143921</td>\n",
       "      <td>-0.041986</td>\n",
       "      <td>0.714192</td>\n",
       "      <td>0.254998</td>\n",
       "      <td>-0.068283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187939</td>\n",
       "      <td>-0.245101</td>\n",
       "      <td>-0.565826</td>\n",
       "      <td>0.227214</td>\n",
       "      <td>-0.206787</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>-0.477272</td>\n",
       "      <td>0.176039</td>\n",
       "      <td>0.420941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198217</td>\n",
       "      <td>-0.065683</td>\n",
       "      <td>-0.453662</td>\n",
       "      <td>-0.159374</td>\n",
       "      <td>-0.330294</td>\n",
       "      <td>-0.241741</td>\n",
       "      <td>0.436773</td>\n",
       "      <td>0.423417</td>\n",
       "      <td>-0.068334</td>\n",
       "      <td>-0.008599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114280</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>-0.615553</td>\n",
       "      <td>0.082351</td>\n",
       "      <td>-0.084131</td>\n",
       "      <td>-0.245042</td>\n",
       "      <td>-0.630190</td>\n",
       "      <td>-0.246156</td>\n",
       "      <td>0.167829</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.574364</td>\n",
       "      <td>0.166891</td>\n",
       "      <td>-0.308708</td>\n",
       "      <td>-0.125461</td>\n",
       "      <td>-0.856284</td>\n",
       "      <td>-0.635108</td>\n",
       "      <td>0.486445</td>\n",
       "      <td>0.802911</td>\n",
       "      <td>0.276931</td>\n",
       "      <td>-0.836928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.585530</td>\n",
       "      <td>-0.714161</td>\n",
       "      <td>-0.674144</td>\n",
       "      <td>-0.016587</td>\n",
       "      <td>-0.359648</td>\n",
       "      <td>-0.071838</td>\n",
       "      <td>-0.346258</td>\n",
       "      <td>-0.364343</td>\n",
       "      <td>0.525816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.362476</td>\n",
       "      <td>-0.240912</td>\n",
       "      <td>-0.305236</td>\n",
       "      <td>-0.117662</td>\n",
       "      <td>-0.365053</td>\n",
       "      <td>-0.539978</td>\n",
       "      <td>0.266043</td>\n",
       "      <td>0.564625</td>\n",
       "      <td>0.414602</td>\n",
       "      <td>-0.354684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275061</td>\n",
       "      <td>-0.292804</td>\n",
       "      <td>-0.609617</td>\n",
       "      <td>-0.576326</td>\n",
       "      <td>0.207753</td>\n",
       "      <td>-0.100599</td>\n",
       "      <td>0.058775</td>\n",
       "      <td>0.376348</td>\n",
       "      <td>0.522347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.007841</td>\n",
       "      <td>-0.369434</td>\n",
       "      <td>-0.231455</td>\n",
       "      <td>-0.052095</td>\n",
       "      <td>-0.572994</td>\n",
       "      <td>-0.259294</td>\n",
       "      <td>0.049462</td>\n",
       "      <td>0.489817</td>\n",
       "      <td>0.617951</td>\n",
       "      <td>-0.202881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369166</td>\n",
       "      <td>-0.290499</td>\n",
       "      <td>-0.400612</td>\n",
       "      <td>-0.223186</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.193803</td>\n",
       "      <td>-0.150293</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.528742</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.146791</td>\n",
       "      <td>-0.517841</td>\n",
       "      <td>-0.283962</td>\n",
       "      <td>-0.350781</td>\n",
       "      <td>-0.263554</td>\n",
       "      <td>-0.182034</td>\n",
       "      <td>0.057058</td>\n",
       "      <td>0.768285</td>\n",
       "      <td>0.151862</td>\n",
       "      <td>-0.097999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022245</td>\n",
       "      <td>-0.462382</td>\n",
       "      <td>-0.275672</td>\n",
       "      <td>0.156045</td>\n",
       "      <td>-0.201733</td>\n",
       "      <td>0.256771</td>\n",
       "      <td>-0.526523</td>\n",
       "      <td>-0.258645</td>\n",
       "      <td>0.478225</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.230309</td>\n",
       "      <td>0.099182</td>\n",
       "      <td>-1.189187</td>\n",
       "      <td>-0.140705</td>\n",
       "      <td>-0.700605</td>\n",
       "      <td>-0.645015</td>\n",
       "      <td>0.148480</td>\n",
       "      <td>0.355590</td>\n",
       "      <td>0.082329</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188880</td>\n",
       "      <td>-0.089098</td>\n",
       "      <td>-0.256621</td>\n",
       "      <td>-0.055487</td>\n",
       "      <td>-0.207184</td>\n",
       "      <td>-0.197762</td>\n",
       "      <td>-0.256311</td>\n",
       "      <td>0.264371</td>\n",
       "      <td>0.465491</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>-0.003287</td>\n",
       "      <td>-0.021032</td>\n",
       "      <td>-0.506837</td>\n",
       "      <td>-0.390883</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.525337</td>\n",
       "      <td>0.261074</td>\n",
       "      <td>0.383272</td>\n",
       "      <td>0.367904</td>\n",
       "      <td>-0.899204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267725</td>\n",
       "      <td>-0.162286</td>\n",
       "      <td>-0.130819</td>\n",
       "      <td>0.144708</td>\n",
       "      <td>0.137884</td>\n",
       "      <td>0.210116</td>\n",
       "      <td>-0.121688</td>\n",
       "      <td>-0.176527</td>\n",
       "      <td>0.891960</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0.050813</td>\n",
       "      <td>-0.109862</td>\n",
       "      <td>-0.298525</td>\n",
       "      <td>-0.183220</td>\n",
       "      <td>-0.511864</td>\n",
       "      <td>-0.125279</td>\n",
       "      <td>0.107218</td>\n",
       "      <td>0.439683</td>\n",
       "      <td>0.341621</td>\n",
       "      <td>-0.316218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280560</td>\n",
       "      <td>-0.269475</td>\n",
       "      <td>-0.487559</td>\n",
       "      <td>-0.216935</td>\n",
       "      <td>0.016401</td>\n",
       "      <td>-0.050369</td>\n",
       "      <td>0.031508</td>\n",
       "      <td>-0.143412</td>\n",
       "      <td>0.408412</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n",
       "0    0.531574 -0.002677 -0.377449 -0.346509 -0.357004 -0.114968 -0.139359   \n",
       "1    0.230405 -0.500298 -0.502653 -0.045785 -0.408853 -0.143921 -0.041986   \n",
       "2    0.198217 -0.065683 -0.453662 -0.159374 -0.330294 -0.241741  0.436773   \n",
       "3   -0.574364  0.166891 -0.308708 -0.125461 -0.856284 -0.635108  0.486445   \n",
       "4    0.362476 -0.240912 -0.305236 -0.117662 -0.365053 -0.539978  0.266043   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "956  0.007841 -0.369434 -0.231455 -0.052095 -0.572994 -0.259294  0.049462   \n",
       "957  0.146791 -0.517841 -0.283962 -0.350781 -0.263554 -0.182034  0.057058   \n",
       "958  0.230309  0.099182 -1.189187 -0.140705 -0.700605 -0.645015  0.148480   \n",
       "959 -0.003287 -0.021032 -0.506837 -0.390883 -0.534432 -0.525337  0.261074   \n",
       "960  0.050813 -0.109862 -0.298525 -0.183220 -0.511864 -0.125279  0.107218   \n",
       "\n",
       "       feat_7    feat_8    feat_9  ...  feat_759  feat_760  feat_761  \\\n",
       "0    0.510641  0.438597 -0.468832  ... -0.395492 -0.281222 -0.151269   \n",
       "1    0.714192  0.254998 -0.068283  ... -0.187939 -0.245101 -0.565826   \n",
       "2    0.423417 -0.068334 -0.008599  ... -0.114280  0.013610 -0.615553   \n",
       "3    0.802911  0.276931 -0.836928  ... -0.585530 -0.714161 -0.674144   \n",
       "4    0.564625  0.414602 -0.354684  ... -0.275061 -0.292804 -0.609617   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "956  0.489817  0.617951 -0.202881  ... -0.369166 -0.290499 -0.400612   \n",
       "957  0.768285  0.151862 -0.097999  ... -0.022245 -0.462382 -0.275672   \n",
       "958  0.355590  0.082329  0.057534  ... -0.188880 -0.089098 -0.256621   \n",
       "959  0.383272  0.367904 -0.899204  ... -0.267725 -0.162286 -0.130819   \n",
       "960  0.439683  0.341621 -0.316218  ... -0.280560 -0.269475 -0.487559   \n",
       "\n",
       "     feat_762  feat_763  feat_764  feat_765  feat_766  feat_767  speaker  \n",
       "0    0.183464 -0.227712  0.016151 -0.106852 -0.075954  0.546363       25  \n",
       "1    0.227214 -0.206787  0.004460 -0.477272  0.176039  0.420941        1  \n",
       "2    0.082351 -0.084131 -0.245042 -0.630190 -0.246156  0.167829       16  \n",
       "3   -0.016587 -0.359648 -0.071838 -0.346258 -0.364343  0.525816        0  \n",
       "4   -0.576326  0.207753 -0.100599  0.058775  0.376348  0.522347        2  \n",
       "..        ...       ...       ...       ...       ...       ...      ...  \n",
       "956 -0.223186  0.004507  0.193803 -0.150293  0.010396  0.528742        7  \n",
       "957  0.156045 -0.201733  0.256771 -0.526523 -0.258645  0.478225       24  \n",
       "958 -0.055487 -0.207184 -0.197762 -0.256311  0.264371  0.465491        3  \n",
       "959  0.144708  0.137884  0.210116 -0.121688 -0.176527  0.891960       15  \n",
       "960 -0.216935  0.016401 -0.050369  0.031508 -0.143412  0.408412       24  \n",
       "\n",
       "[961 rows x 769 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df[\"speaker\"] = x_train_speakers[\"speaker\"]\n",
    "x_test_df[\"speaker\"] = x_test_speakers[\"speaker\"]\n",
    "x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4a495c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5, class_weight=&#x27;balanced&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5, class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5, class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report, best_est = svm_classifier(x_train_df, x_test_df, y_train, y_test)\n",
    "best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41bd681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7308    0.6281    0.6756       121\n",
      "         1.0     0.6715    0.7667    0.7160       120\n",
      "\n",
      "    accuracy                         0.6971       241\n",
      "   macro avg     0.7012    0.6974    0.6958       241\n",
      "weighted avg     0.7013    0.6971    0.6957       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4588ad2",
   "metadata": {},
   "source": [
    "### Speaker Independent and Context dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17df71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../text_features/bert_embeddings/train_bert_embeddings_target_context.pkl', 'rb') as f:\n",
    "    x_train_context = pickle.load(f, encoding='latin1')\n",
    "\n",
    "with open('../../text_features/bert_embeddings/test_bert_embeddings_target_context.pkl', 'rb') as f:\n",
    "    x_test_context = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833cf58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vals = []\n",
    "for sample in x_train_context[\"embeddings\"]:\n",
    "    x_train_vals.append(sample[0].tolist())\n",
    "    \n",
    "x_test_vals = []\n",
    "for sample in x_test_context[\"embeddings\"]:\n",
    "    x_test_vals.append(sample[0].tolist())\n",
    "\n",
    "x_train_df = pd.DataFrame({'embeddings':x_train_vals})\n",
    "x_test_df = pd.DataFrame({'embeddings':x_test_vals})\n",
    "\n",
    "def process_dataframes(data):\n",
    "    temp_concat = pd.concat([data, data.embeddings.apply(pd.Series)], axis=1)\n",
    "    temp_concat.drop(columns=['embeddings'], inplace = True)\n",
    "    return temp_concat.add_prefix('feat_')\n",
    "\n",
    "x_train_df = process_dataframes(x_train_df)\n",
    "x_test_df = process_dataframes(x_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8797ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "report, best_est = svm_classifier(x_train_df, x_test_df, y_train.values.ravel(), y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f77dcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5, class_weight=&#x27;balanced&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5, class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5, class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7b8eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5985    0.6529    0.6245       121\n",
      "         1.0     0.6147    0.5583    0.5852       120\n",
      "\n",
      "    accuracy                         0.6058       241\n",
      "   macro avg     0.6066    0.6056    0.6048       241\n",
      "weighted avg     0.6065    0.6058    0.6049       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43dcda2",
   "metadata": {},
   "source": [
    "### Speaker Dependent and Context Dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cee7ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_759</th>\n",
       "      <th>feat_760</th>\n",
       "      <th>feat_761</th>\n",
       "      <th>feat_762</th>\n",
       "      <th>feat_763</th>\n",
       "      <th>feat_764</th>\n",
       "      <th>feat_765</th>\n",
       "      <th>feat_766</th>\n",
       "      <th>feat_767</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574635</td>\n",
       "      <td>-0.695604</td>\n",
       "      <td>-0.290111</td>\n",
       "      <td>-0.501525</td>\n",
       "      <td>-0.111114</td>\n",
       "      <td>0.033933</td>\n",
       "      <td>-0.064401</td>\n",
       "      <td>0.372059</td>\n",
       "      <td>0.276928</td>\n",
       "      <td>-0.154529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542819</td>\n",
       "      <td>-0.312360</td>\n",
       "      <td>-0.841467</td>\n",
       "      <td>-0.249062</td>\n",
       "      <td>-0.188382</td>\n",
       "      <td>-0.034155</td>\n",
       "      <td>-0.304036</td>\n",
       "      <td>-0.002833</td>\n",
       "      <td>0.474112</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009401</td>\n",
       "      <td>-0.713261</td>\n",
       "      <td>-0.092869</td>\n",
       "      <td>-0.188030</td>\n",
       "      <td>-0.583256</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>0.144762</td>\n",
       "      <td>-0.005990</td>\n",
       "      <td>-0.176591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016617</td>\n",
       "      <td>-0.309293</td>\n",
       "      <td>-0.677562</td>\n",
       "      <td>-0.093774</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.034902</td>\n",
       "      <td>0.021323</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>0.312115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210755</td>\n",
       "      <td>-0.549721</td>\n",
       "      <td>-0.031042</td>\n",
       "      <td>-0.318841</td>\n",
       "      <td>-0.471447</td>\n",
       "      <td>-0.455262</td>\n",
       "      <td>0.248838</td>\n",
       "      <td>0.352645</td>\n",
       "      <td>0.497266</td>\n",
       "      <td>-0.114562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077138</td>\n",
       "      <td>-0.524917</td>\n",
       "      <td>-0.786684</td>\n",
       "      <td>-0.052215</td>\n",
       "      <td>0.113616</td>\n",
       "      <td>0.067762</td>\n",
       "      <td>-0.151070</td>\n",
       "      <td>0.065819</td>\n",
       "      <td>0.390655</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032532</td>\n",
       "      <td>-0.666678</td>\n",
       "      <td>0.111073</td>\n",
       "      <td>-0.566707</td>\n",
       "      <td>-0.629884</td>\n",
       "      <td>-0.351460</td>\n",
       "      <td>0.293653</td>\n",
       "      <td>0.135274</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>-0.237507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027932</td>\n",
       "      <td>-0.491872</td>\n",
       "      <td>-0.768082</td>\n",
       "      <td>-0.060602</td>\n",
       "      <td>-0.096596</td>\n",
       "      <td>-0.065277</td>\n",
       "      <td>-0.009771</td>\n",
       "      <td>0.048125</td>\n",
       "      <td>0.485839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.511843</td>\n",
       "      <td>-0.130731</td>\n",
       "      <td>-0.288622</td>\n",
       "      <td>-0.338487</td>\n",
       "      <td>-0.499926</td>\n",
       "      <td>-0.658664</td>\n",
       "      <td>0.347511</td>\n",
       "      <td>0.401867</td>\n",
       "      <td>0.203338</td>\n",
       "      <td>-0.103752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.569898</td>\n",
       "      <td>-0.268881</td>\n",
       "      <td>-0.146304</td>\n",
       "      <td>-0.428675</td>\n",
       "      <td>0.079669</td>\n",
       "      <td>-0.125833</td>\n",
       "      <td>-0.068329</td>\n",
       "      <td>0.323887</td>\n",
       "      <td>0.390050</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.167014</td>\n",
       "      <td>-0.660699</td>\n",
       "      <td>0.046890</td>\n",
       "      <td>-0.320457</td>\n",
       "      <td>-0.222541</td>\n",
       "      <td>-0.203675</td>\n",
       "      <td>0.082216</td>\n",
       "      <td>0.091342</td>\n",
       "      <td>0.252586</td>\n",
       "      <td>-0.353422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444565</td>\n",
       "      <td>-0.359013</td>\n",
       "      <td>-0.615910</td>\n",
       "      <td>0.007245</td>\n",
       "      <td>0.021878</td>\n",
       "      <td>0.238162</td>\n",
       "      <td>0.252142</td>\n",
       "      <td>0.068272</td>\n",
       "      <td>0.301823</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.138407</td>\n",
       "      <td>-0.448751</td>\n",
       "      <td>-0.334320</td>\n",
       "      <td>-0.477100</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>-0.229950</td>\n",
       "      <td>0.317996</td>\n",
       "      <td>0.434057</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>-0.180775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194911</td>\n",
       "      <td>-0.291315</td>\n",
       "      <td>-0.595891</td>\n",
       "      <td>-0.007889</td>\n",
       "      <td>0.206415</td>\n",
       "      <td>-0.019882</td>\n",
       "      <td>-0.210651</td>\n",
       "      <td>0.226619</td>\n",
       "      <td>0.770230</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.151957</td>\n",
       "      <td>-0.593120</td>\n",
       "      <td>-0.360247</td>\n",
       "      <td>-0.185420</td>\n",
       "      <td>-0.694859</td>\n",
       "      <td>-0.258243</td>\n",
       "      <td>-0.187632</td>\n",
       "      <td>0.114319</td>\n",
       "      <td>0.363445</td>\n",
       "      <td>-0.348429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021035</td>\n",
       "      <td>-0.220124</td>\n",
       "      <td>-0.451208</td>\n",
       "      <td>0.222772</td>\n",
       "      <td>-0.197227</td>\n",
       "      <td>-0.212523</td>\n",
       "      <td>0.363826</td>\n",
       "      <td>0.316671</td>\n",
       "      <td>0.352101</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0.223559</td>\n",
       "      <td>-0.728716</td>\n",
       "      <td>0.137703</td>\n",
       "      <td>-0.223860</td>\n",
       "      <td>-0.123140</td>\n",
       "      <td>-0.209221</td>\n",
       "      <td>-0.093874</td>\n",
       "      <td>0.517305</td>\n",
       "      <td>-0.097130</td>\n",
       "      <td>-0.260613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160411</td>\n",
       "      <td>-0.655506</td>\n",
       "      <td>-0.872614</td>\n",
       "      <td>0.312203</td>\n",
       "      <td>0.227483</td>\n",
       "      <td>-0.191332</td>\n",
       "      <td>-0.094120</td>\n",
       "      <td>0.325375</td>\n",
       "      <td>0.292900</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0.175244</td>\n",
       "      <td>-0.327932</td>\n",
       "      <td>-0.220004</td>\n",
       "      <td>-0.333306</td>\n",
       "      <td>-0.441649</td>\n",
       "      <td>-0.258047</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>0.245040</td>\n",
       "      <td>0.523751</td>\n",
       "      <td>-0.164971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362197</td>\n",
       "      <td>-0.265929</td>\n",
       "      <td>-0.715539</td>\n",
       "      <td>-0.332236</td>\n",
       "      <td>0.116371</td>\n",
       "      <td>-0.072845</td>\n",
       "      <td>0.156106</td>\n",
       "      <td>-0.036805</td>\n",
       "      <td>0.556564</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n",
       "0    0.574635 -0.695604 -0.290111 -0.501525 -0.111114  0.033933 -0.064401   \n",
       "1   -0.009401 -0.713261 -0.092869 -0.188030 -0.583256  0.038700 -0.012739   \n",
       "2    0.210755 -0.549721 -0.031042 -0.318841 -0.471447 -0.455262  0.248838   \n",
       "3    0.032532 -0.666678  0.111073 -0.566707 -0.629884 -0.351460  0.293653   \n",
       "4    0.511843 -0.130731 -0.288622 -0.338487 -0.499926 -0.658664  0.347511   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "956  0.167014 -0.660699  0.046890 -0.320457 -0.222541 -0.203675  0.082216   \n",
       "957  0.138407 -0.448751 -0.334320 -0.477100 -0.440597 -0.229950  0.317996   \n",
       "958  0.151957 -0.593120 -0.360247 -0.185420 -0.694859 -0.258243 -0.187632   \n",
       "959  0.223559 -0.728716  0.137703 -0.223860 -0.123140 -0.209221 -0.093874   \n",
       "960  0.175244 -0.327932 -0.220004 -0.333306 -0.441649 -0.258047  0.070518   \n",
       "\n",
       "       feat_7    feat_8    feat_9  ...  feat_759  feat_760  feat_761  \\\n",
       "0    0.372059  0.276928 -0.154529  ... -0.542819 -0.312360 -0.841467   \n",
       "1    0.144762 -0.005990 -0.176591  ... -0.016617 -0.309293 -0.677562   \n",
       "2    0.352645  0.497266 -0.114562  ... -0.077138 -0.524917 -0.786684   \n",
       "3    0.135274 -0.025899 -0.237507  ... -0.027932 -0.491872 -0.768082   \n",
       "4    0.401867  0.203338 -0.103752  ... -0.569898 -0.268881 -0.146304   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "956  0.091342  0.252586 -0.353422  ... -0.444565 -0.359013 -0.615910   \n",
       "957  0.434057  0.261300 -0.180775  ... -0.194911 -0.291315 -0.595891   \n",
       "958  0.114319  0.363445 -0.348429  ...  0.021035 -0.220124 -0.451208   \n",
       "959  0.517305 -0.097130 -0.260613  ... -0.160411 -0.655506 -0.872614   \n",
       "960  0.245040  0.523751 -0.164971  ... -0.362197 -0.265929 -0.715539   \n",
       "\n",
       "     feat_762  feat_763  feat_764  feat_765  feat_766  feat_767  speaker  \n",
       "0   -0.249062 -0.188382 -0.034155 -0.304036 -0.002833  0.474112       25  \n",
       "1   -0.093774  0.027813  0.034902  0.021323 -0.005110  0.312115        1  \n",
       "2   -0.052215  0.113616  0.067762 -0.151070  0.065819  0.390655       16  \n",
       "3   -0.060602 -0.096596 -0.065277 -0.009771  0.048125  0.485839        0  \n",
       "4   -0.428675  0.079669 -0.125833 -0.068329  0.323887  0.390050        2  \n",
       "..        ...       ...       ...       ...       ...       ...      ...  \n",
       "956  0.007245  0.021878  0.238162  0.252142  0.068272  0.301823        7  \n",
       "957 -0.007889  0.206415 -0.019882 -0.210651  0.226619  0.770230       24  \n",
       "958  0.222772 -0.197227 -0.212523  0.363826  0.316671  0.352101        3  \n",
       "959  0.312203  0.227483 -0.191332 -0.094120  0.325375  0.292900       15  \n",
       "960 -0.332236  0.116371 -0.072845  0.156106 -0.036805  0.556564       24  \n",
       "\n",
       "[961 rows x 769 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df[\"speaker\"] = x_train_speakers[\"speaker\"]\n",
    "x_test_df[\"speaker\"] = x_test_speakers[\"speaker\"]\n",
    "x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9446dfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, class_weight=&#x27;balanced&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report, best_est = svm_classifier(x_train_df, x_test_df, y_train.values.ravel(), y_test.values.ravel())\n",
    "best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fda38afc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6015    0.6612    0.6299       121\n",
      "         1.0     0.6204    0.5583    0.5877       120\n",
      "\n",
      "    accuracy                         0.6100       241\n",
      "   macro avg     0.6109    0.6097    0.6088       241\n",
      "weighted avg     0.6109    0.6100    0.6089       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
