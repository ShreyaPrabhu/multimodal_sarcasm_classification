{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42e3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3da61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(X_train, X_test, Y_train, Y_test):\n",
    "    svm_clf = svm.SVC(random_state=0, kernel = \"rbf\", gamma = \"scale\", class_weight = \"balanced\")\n",
    "    C = C = [0.0001, 0.0003, 0.0005, 0.001, 0.003, 0.005, 0.01, 0.03, 0.05, 0.1, 0.3, 0.5, 1, 3, 5, 10]\n",
    "    gscv_clf = GridSearchCV(\n",
    "        estimator=svm_clf, \n",
    "        param_grid=dict(C=C),\n",
    "        n_jobs=-1, \n",
    "        cv = 10, \n",
    "        scoring = 'f1_weighted', \n",
    "        refit = True)\n",
    "\n",
    "    gscv_clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = gscv_clf.predict(X_test)\n",
    "    report = classification_report(Y_test, Y_test_pred, digits=4)\n",
    "    return report, gscv_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a94847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/lexical/text_feature_extraction/Emotion Roberta/embeddings/train_labels.csv\")\n",
    "y_test = pd.read_csv(\"/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/lexical/text_feature_extraction/Emotion Roberta/embeddings/test_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386872bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/lexical/text_feature_extraction/Emotion Roberta/embeddings/train_emoberta_embeddings_target_.pkl', 'rb') as f:\n",
    "    x_train = pickle.load(f, encoding='latin1')\n",
    "\n",
    "with open('/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/lexical/text_feature_extraction/Emotion Roberta/embeddings/test_emoberta_embeddings_target_.pkl', 'rb') as f:\n",
    "    x_test = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e07749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vals = []\n",
    "for sample in x_train[\"embeddings\"]:\n",
    "    x_train_vals.append(sample[0].tolist())\n",
    "    \n",
    "x_test_vals = []\n",
    "for sample in x_test[\"embeddings\"]:\n",
    "    x_test_vals.append(sample[0].tolist())\n",
    "\n",
    "x_train_df = pd.DataFrame({'embeddings':x_train_vals})\n",
    "x_test_df = pd.DataFrame({'embeddings':x_test_vals})\n",
    "\n",
    "def process_dataframes(data):\n",
    "    temp_concat = pd.concat([data, data.embeddings.apply(pd.Series)], axis=1)\n",
    "    temp_concat.drop(columns=['embeddings'], inplace = True)\n",
    "    return temp_concat.add_prefix('feat_')\n",
    "\n",
    "x_train_df = process_dataframes(x_train_df)\n",
    "x_test_df = process_dataframes(x_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c7bb360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_758</th>\n",
       "      <th>feat_759</th>\n",
       "      <th>feat_760</th>\n",
       "      <th>feat_761</th>\n",
       "      <th>feat_762</th>\n",
       "      <th>feat_763</th>\n",
       "      <th>feat_764</th>\n",
       "      <th>feat_765</th>\n",
       "      <th>feat_766</th>\n",
       "      <th>feat_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.346661</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.176457</td>\n",
       "      <td>-0.430842</td>\n",
       "      <td>0.133689</td>\n",
       "      <td>0.069174</td>\n",
       "      <td>0.162834</td>\n",
       "      <td>-0.316667</td>\n",
       "      <td>0.685901</td>\n",
       "      <td>0.066745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177601</td>\n",
       "      <td>0.071811</td>\n",
       "      <td>0.426316</td>\n",
       "      <td>0.393841</td>\n",
       "      <td>0.417978</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>-0.450451</td>\n",
       "      <td>0.052605</td>\n",
       "      <td>-0.092888</td>\n",
       "      <td>-0.107823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211392</td>\n",
       "      <td>-0.113207</td>\n",
       "      <td>-0.149064</td>\n",
       "      <td>-0.718321</td>\n",
       "      <td>0.149626</td>\n",
       "      <td>-0.030859</td>\n",
       "      <td>-0.398602</td>\n",
       "      <td>-0.755846</td>\n",
       "      <td>0.409559</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151625</td>\n",
       "      <td>0.682756</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>0.516527</td>\n",
       "      <td>-0.091031</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.122272</td>\n",
       "      <td>0.255122</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>-0.075256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.130957</td>\n",
       "      <td>-0.344759</td>\n",
       "      <td>-0.049595</td>\n",
       "      <td>-0.384732</td>\n",
       "      <td>0.192853</td>\n",
       "      <td>-0.511049</td>\n",
       "      <td>0.218240</td>\n",
       "      <td>0.072904</td>\n",
       "      <td>0.326533</td>\n",
       "      <td>0.097631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060887</td>\n",
       "      <td>0.568969</td>\n",
       "      <td>-0.035156</td>\n",
       "      <td>0.448589</td>\n",
       "      <td>0.097846</td>\n",
       "      <td>0.080323</td>\n",
       "      <td>-0.422726</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.076732</td>\n",
       "      <td>0.074437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.166356</td>\n",
       "      <td>0.177973</td>\n",
       "      <td>-0.197496</td>\n",
       "      <td>-0.417468</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>-0.160716</td>\n",
       "      <td>-0.434448</td>\n",
       "      <td>-0.526498</td>\n",
       "      <td>0.642250</td>\n",
       "      <td>-0.146033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108388</td>\n",
       "      <td>0.250758</td>\n",
       "      <td>0.211999</td>\n",
       "      <td>0.724478</td>\n",
       "      <td>0.361014</td>\n",
       "      <td>0.227494</td>\n",
       "      <td>-0.208437</td>\n",
       "      <td>0.449303</td>\n",
       "      <td>-0.062656</td>\n",
       "      <td>0.356658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.144698</td>\n",
       "      <td>-0.360290</td>\n",
       "      <td>-0.123821</td>\n",
       "      <td>-0.626001</td>\n",
       "      <td>-0.146996</td>\n",
       "      <td>-0.377608</td>\n",
       "      <td>-0.096727</td>\n",
       "      <td>-0.185140</td>\n",
       "      <td>0.437847</td>\n",
       "      <td>0.149392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.205276</td>\n",
       "      <td>0.113454</td>\n",
       "      <td>0.134896</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>-0.065591</td>\n",
       "      <td>-0.144461</td>\n",
       "      <td>-0.065818</td>\n",
       "      <td>0.097677</td>\n",
       "      <td>-0.109731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n",
       "0 -0.346661 -0.076316 -0.176457 -0.430842  0.133689  0.069174  0.162834   \n",
       "1 -0.211392 -0.113207 -0.149064 -0.718321  0.149626 -0.030859 -0.398602   \n",
       "2 -0.130957 -0.344759 -0.049595 -0.384732  0.192853 -0.511049  0.218240   \n",
       "3 -0.166356  0.177973 -0.197496 -0.417468  0.009837 -0.160716 -0.434448   \n",
       "4 -0.144698 -0.360290 -0.123821 -0.626001 -0.146996 -0.377608 -0.096727   \n",
       "\n",
       "     feat_7    feat_8    feat_9  ...  feat_758  feat_759  feat_760  feat_761  \\\n",
       "0 -0.316667  0.685901  0.066745  ... -0.177601  0.071811  0.426316  0.393841   \n",
       "1 -0.755846  0.409559  0.227644  ... -0.151625  0.682756  0.130624  0.516527   \n",
       "2  0.072904  0.326533  0.097631  ... -0.060887  0.568969 -0.035156  0.448589   \n",
       "3 -0.526498  0.642250 -0.146033  ... -0.108388  0.250758  0.211999  0.724478   \n",
       "4 -0.185140  0.437847  0.149392  ...  0.001158  0.205276  0.113454  0.134896   \n",
       "\n",
       "   feat_762  feat_763  feat_764  feat_765  feat_766  feat_767  \n",
       "0  0.417978  0.104095 -0.450451  0.052605 -0.092888 -0.107823  \n",
       "1 -0.091031  0.005343  0.122272  0.255122  0.013893 -0.075256  \n",
       "2  0.097846  0.080323 -0.422726  0.010065  0.076732  0.074437  \n",
       "3  0.361014  0.227494 -0.208437  0.449303 -0.062656  0.356658  \n",
       "4  0.142800 -0.065591 -0.144461 -0.065818  0.097677 -0.109731  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d92cc",
   "metadata": {},
   "source": [
    "### Speaker Independent and Context Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a887b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report, best_est = svm_classifier(x_train_df, x_test_df, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709f8378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5, class_weight=&#x27;balanced&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5, class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5, class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e8058be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5840    0.6033    0.5935       121\n",
      "         1.0     0.5862    0.5667    0.5763       120\n",
      "\n",
      "    accuracy                         0.5851       241\n",
      "   macro avg     0.5851    0.5850    0.5849       241\n",
      "weighted avg     0.5851    0.5851    0.5849       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa6494",
   "metadata": {},
   "source": [
    "### Speaker Dependent and Context Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47110585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_</th>\n",
       "      <th>target_context</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;  i have been told it is a good way to move...</td>\n",
       "      <td>&lt;s&gt;  i have been told it is a good way to move...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;  yeah, sure. you slept with your husband. ...</td>\n",
       "      <td>&lt;s&gt;  yeah, sure. you slept with your husband. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt;  when are you coming home? &lt;/s&gt;</td>\n",
       "      <td>&lt;s&gt;  when are you coming home?  okay. alright....</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt;  riveting. &lt;/s&gt;</td>\n",
       "      <td>&lt;s&gt;  riveting.  bingo. then i lifted the cushi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt;  no, this is just part of a daredevil game...</td>\n",
       "      <td>&lt;s&gt;  no, this is just part of a daredevil game...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>&lt;s&gt;  oh, that is sweet, but today is all about...</td>\n",
       "      <td>&lt;s&gt;  oh, that is sweet, but today is all about...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>&lt;s&gt;  if you want to put a label on it. &lt;/s&gt;</td>\n",
       "      <td>&lt;s&gt;  if you want to put a label on it.  you me...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>&lt;s&gt;  that you are an alcoholic? &lt;/s&gt;</td>\n",
       "      <td>&lt;s&gt;  that you are an alcoholic?  i realized so...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>&lt;s&gt;  all i see is a yellow smudge. &lt;/s&gt;</td>\n",
       "      <td>&lt;s&gt;  all i see is a yellow smudge.  now go bac...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>&lt;s&gt;  i mean if you had not initiated it i-i-i ...</td>\n",
       "      <td>&lt;s&gt;  i mean if you had not initiated it i-i-i ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               target_  \\\n",
       "0    <s>  i have been told it is a good way to move...   \n",
       "1    <s>  yeah, sure. you slept with your husband. ...   \n",
       "2                  <s>  when are you coming home? </s>   \n",
       "3                                  <s>  riveting. </s>   \n",
       "4    <s>  no, this is just part of a daredevil game...   \n",
       "..                                                 ...   \n",
       "956  <s>  oh, that is sweet, but today is all about...   \n",
       "957        <s>  if you want to put a label on it. </s>   \n",
       "958               <s>  that you are an alcoholic? </s>   \n",
       "959            <s>  all i see is a yellow smudge. </s>   \n",
       "960  <s>  i mean if you had not initiated it i-i-i ...   \n",
       "\n",
       "                                        target_context  speaker  \n",
       "0    <s>  i have been told it is a good way to move...       25  \n",
       "1    <s>  yeah, sure. you slept with your husband. ...        1  \n",
       "2    <s>  when are you coming home?  okay. alright....       16  \n",
       "3    <s>  riveting.  bingo. then i lifted the cushi...        0  \n",
       "4    <s>  no, this is just part of a daredevil game...        2  \n",
       "..                                                 ...      ...  \n",
       "956  <s>  oh, that is sweet, but today is all about...        7  \n",
       "957  <s>  if you want to put a label on it.  you me...       24  \n",
       "958  <s>  that you are an alcoholic?  i realized so...        3  \n",
       "959  <s>  all i see is a yellow smudge.  now go bac...       15  \n",
       "960  <s>  i mean if you had not initiated it i-i-i ...       24  \n",
       "\n",
       "[961 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_speakers = pd.read_csv(\"/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/lexical/text_feature_extraction/Emotion Roberta/embeddings/train_data.csv\")\n",
    "x_test_speakers = pd.read_csv(\"/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/lexical/text_feature_extraction/Emotion Roberta/embeddings/test_data.csv\")\n",
    "x_train_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e76e6fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_759</th>\n",
       "      <th>feat_760</th>\n",
       "      <th>feat_761</th>\n",
       "      <th>feat_762</th>\n",
       "      <th>feat_763</th>\n",
       "      <th>feat_764</th>\n",
       "      <th>feat_765</th>\n",
       "      <th>feat_766</th>\n",
       "      <th>feat_767</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.346661</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.176457</td>\n",
       "      <td>-0.430842</td>\n",
       "      <td>0.133689</td>\n",
       "      <td>0.069174</td>\n",
       "      <td>0.162834</td>\n",
       "      <td>-0.316667</td>\n",
       "      <td>0.685901</td>\n",
       "      <td>0.066745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071811</td>\n",
       "      <td>0.426316</td>\n",
       "      <td>0.393841</td>\n",
       "      <td>0.417978</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>-0.450451</td>\n",
       "      <td>0.052605</td>\n",
       "      <td>-0.092888</td>\n",
       "      <td>-0.107823</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211392</td>\n",
       "      <td>-0.113207</td>\n",
       "      <td>-0.149064</td>\n",
       "      <td>-0.718321</td>\n",
       "      <td>0.149626</td>\n",
       "      <td>-0.030859</td>\n",
       "      <td>-0.398602</td>\n",
       "      <td>-0.755846</td>\n",
       "      <td>0.409559</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682756</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>0.516527</td>\n",
       "      <td>-0.091031</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.122272</td>\n",
       "      <td>0.255122</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>-0.075256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.130957</td>\n",
       "      <td>-0.344759</td>\n",
       "      <td>-0.049595</td>\n",
       "      <td>-0.384732</td>\n",
       "      <td>0.192853</td>\n",
       "      <td>-0.511049</td>\n",
       "      <td>0.218240</td>\n",
       "      <td>0.072904</td>\n",
       "      <td>0.326533</td>\n",
       "      <td>0.097631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568969</td>\n",
       "      <td>-0.035156</td>\n",
       "      <td>0.448589</td>\n",
       "      <td>0.097846</td>\n",
       "      <td>0.080323</td>\n",
       "      <td>-0.422726</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.076732</td>\n",
       "      <td>0.074437</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.166356</td>\n",
       "      <td>0.177973</td>\n",
       "      <td>-0.197496</td>\n",
       "      <td>-0.417468</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>-0.160716</td>\n",
       "      <td>-0.434448</td>\n",
       "      <td>-0.526498</td>\n",
       "      <td>0.642250</td>\n",
       "      <td>-0.146033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250758</td>\n",
       "      <td>0.211999</td>\n",
       "      <td>0.724478</td>\n",
       "      <td>0.361014</td>\n",
       "      <td>0.227494</td>\n",
       "      <td>-0.208437</td>\n",
       "      <td>0.449303</td>\n",
       "      <td>-0.062656</td>\n",
       "      <td>0.356658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.144698</td>\n",
       "      <td>-0.360290</td>\n",
       "      <td>-0.123821</td>\n",
       "      <td>-0.626001</td>\n",
       "      <td>-0.146996</td>\n",
       "      <td>-0.377608</td>\n",
       "      <td>-0.096727</td>\n",
       "      <td>-0.185140</td>\n",
       "      <td>0.437847</td>\n",
       "      <td>0.149392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205276</td>\n",
       "      <td>0.113454</td>\n",
       "      <td>0.134896</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>-0.065591</td>\n",
       "      <td>-0.144461</td>\n",
       "      <td>-0.065818</td>\n",
       "      <td>0.097677</td>\n",
       "      <td>-0.109731</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.105888</td>\n",
       "      <td>0.100209</td>\n",
       "      <td>-0.053107</td>\n",
       "      <td>-0.519480</td>\n",
       "      <td>0.287733</td>\n",
       "      <td>0.153177</td>\n",
       "      <td>-0.062070</td>\n",
       "      <td>-0.301622</td>\n",
       "      <td>0.466676</td>\n",
       "      <td>0.199987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217009</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.300264</td>\n",
       "      <td>0.248019</td>\n",
       "      <td>0.092152</td>\n",
       "      <td>-0.073072</td>\n",
       "      <td>-0.013160</td>\n",
       "      <td>-0.019867</td>\n",
       "      <td>0.131380</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>-0.081320</td>\n",
       "      <td>-0.063892</td>\n",
       "      <td>-0.166051</td>\n",
       "      <td>-0.409307</td>\n",
       "      <td>-0.285387</td>\n",
       "      <td>-0.208739</td>\n",
       "      <td>-0.105344</td>\n",
       "      <td>-0.510182</td>\n",
       "      <td>0.453736</td>\n",
       "      <td>-0.352903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202251</td>\n",
       "      <td>-0.066086</td>\n",
       "      <td>0.495700</td>\n",
       "      <td>0.105306</td>\n",
       "      <td>0.194420</td>\n",
       "      <td>-0.259736</td>\n",
       "      <td>0.530509</td>\n",
       "      <td>-0.057561</td>\n",
       "      <td>-0.011852</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>-0.123531</td>\n",
       "      <td>-0.132446</td>\n",
       "      <td>-0.101091</td>\n",
       "      <td>-0.686636</td>\n",
       "      <td>-0.035489</td>\n",
       "      <td>-0.223620</td>\n",
       "      <td>0.190708</td>\n",
       "      <td>-0.076541</td>\n",
       "      <td>0.147838</td>\n",
       "      <td>0.057696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761178</td>\n",
       "      <td>-0.089701</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>-0.267968</td>\n",
       "      <td>-0.008222</td>\n",
       "      <td>-0.567253</td>\n",
       "      <td>0.195762</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>-0.356796</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0.003655</td>\n",
       "      <td>-0.216856</td>\n",
       "      <td>-0.378327</td>\n",
       "      <td>-0.563901</td>\n",
       "      <td>0.132323</td>\n",
       "      <td>-0.456657</td>\n",
       "      <td>-0.129780</td>\n",
       "      <td>-0.321604</td>\n",
       "      <td>0.082073</td>\n",
       "      <td>-0.140326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072743</td>\n",
       "      <td>0.036093</td>\n",
       "      <td>0.347542</td>\n",
       "      <td>-0.491985</td>\n",
       "      <td>0.044802</td>\n",
       "      <td>-0.406558</td>\n",
       "      <td>-0.036060</td>\n",
       "      <td>0.086675</td>\n",
       "      <td>-0.218487</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-0.204830</td>\n",
       "      <td>-0.195005</td>\n",
       "      <td>-0.060721</td>\n",
       "      <td>-0.542080</td>\n",
       "      <td>0.103010</td>\n",
       "      <td>-0.436128</td>\n",
       "      <td>0.018159</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.239336</td>\n",
       "      <td>-0.061297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590343</td>\n",
       "      <td>-0.039911</td>\n",
       "      <td>0.494651</td>\n",
       "      <td>0.161080</td>\n",
       "      <td>-0.261634</td>\n",
       "      <td>-0.405890</td>\n",
       "      <td>-0.076027</td>\n",
       "      <td>-0.120991</td>\n",
       "      <td>-0.023981</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n",
       "0   -0.346661 -0.076316 -0.176457 -0.430842  0.133689  0.069174  0.162834   \n",
       "1   -0.211392 -0.113207 -0.149064 -0.718321  0.149626 -0.030859 -0.398602   \n",
       "2   -0.130957 -0.344759 -0.049595 -0.384732  0.192853 -0.511049  0.218240   \n",
       "3   -0.166356  0.177973 -0.197496 -0.417468  0.009837 -0.160716 -0.434448   \n",
       "4   -0.144698 -0.360290 -0.123821 -0.626001 -0.146996 -0.377608 -0.096727   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "956  0.105888  0.100209 -0.053107 -0.519480  0.287733  0.153177 -0.062070   \n",
       "957 -0.081320 -0.063892 -0.166051 -0.409307 -0.285387 -0.208739 -0.105344   \n",
       "958 -0.123531 -0.132446 -0.101091 -0.686636 -0.035489 -0.223620  0.190708   \n",
       "959  0.003655 -0.216856 -0.378327 -0.563901  0.132323 -0.456657 -0.129780   \n",
       "960 -0.204830 -0.195005 -0.060721 -0.542080  0.103010 -0.436128  0.018159   \n",
       "\n",
       "       feat_7    feat_8    feat_9  ...  feat_759  feat_760  feat_761  \\\n",
       "0   -0.316667  0.685901  0.066745  ...  0.071811  0.426316  0.393841   \n",
       "1   -0.755846  0.409559  0.227644  ...  0.682756  0.130624  0.516527   \n",
       "2    0.072904  0.326533  0.097631  ...  0.568969 -0.035156  0.448589   \n",
       "3   -0.526498  0.642250 -0.146033  ...  0.250758  0.211999  0.724478   \n",
       "4   -0.185140  0.437847  0.149392  ...  0.205276  0.113454  0.134896   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "956 -0.301622  0.466676  0.199987  ...  0.217009  0.255100  0.300264   \n",
       "957 -0.510182  0.453736 -0.352903  ...  0.202251 -0.066086  0.495700   \n",
       "958 -0.076541  0.147838  0.057696  ...  0.761178 -0.089701  0.299700   \n",
       "959 -0.321604  0.082073 -0.140326  ...  0.072743  0.036093  0.347542   \n",
       "960  0.006546  0.239336 -0.061297  ...  0.590343 -0.039911  0.494651   \n",
       "\n",
       "     feat_762  feat_763  feat_764  feat_765  feat_766  feat_767  speaker  \n",
       "0    0.417978  0.104095 -0.450451  0.052605 -0.092888 -0.107823       25  \n",
       "1   -0.091031  0.005343  0.122272  0.255122  0.013893 -0.075256        1  \n",
       "2    0.097846  0.080323 -0.422726  0.010065  0.076732  0.074437       16  \n",
       "3    0.361014  0.227494 -0.208437  0.449303 -0.062656  0.356658        0  \n",
       "4    0.142800 -0.065591 -0.144461 -0.065818  0.097677 -0.109731        2  \n",
       "..        ...       ...       ...       ...       ...       ...      ...  \n",
       "956  0.248019  0.092152 -0.073072 -0.013160 -0.019867  0.131380        7  \n",
       "957  0.105306  0.194420 -0.259736  0.530509 -0.057561 -0.011852       24  \n",
       "958 -0.267968 -0.008222 -0.567253  0.195762  0.011469 -0.356796        3  \n",
       "959 -0.491985  0.044802 -0.406558 -0.036060  0.086675 -0.218487       15  \n",
       "960  0.161080 -0.261634 -0.405890 -0.076027 -0.120991 -0.023981       24  \n",
       "\n",
       "[961 rows x 769 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df[\"speaker\"] = x_train_speakers[\"speaker\"]\n",
    "x_test_df[\"speaker\"] = x_test_speakers[\"speaker\"]\n",
    "x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a495c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5, class_weight=&#x27;balanced&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5, class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5, class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report, best_est = svm_classifier(x_train_df, x_test_df, y_train, y_test)\n",
    "best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41bd681e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6852    0.6116    0.6463       121\n",
      "         1.0     0.6466    0.7167    0.6798       120\n",
      "\n",
      "    accuracy                         0.6639       241\n",
      "   macro avg     0.6659    0.6641    0.6631       241\n",
      "weighted avg     0.6660    0.6639    0.6630       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4588ad2",
   "metadata": {},
   "source": [
    "### Speaker Independent and Context dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17df71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/lexical/text_feature_extraction/Emotion Roberta/embeddings/train_emoberta_embeddings_target_context.pkl', 'rb') as f:\n",
    "    x_train_context = pickle.load(f, encoding='latin1')\n",
    "\n",
    "with open('/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/lexical/text_feature_extraction/Emotion Roberta/embeddings/test_emoberta_embeddings_target_context.pkl', 'rb') as f:\n",
    "    x_test_context = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "833cf58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vals = []\n",
    "for sample in x_train_context[\"embeddings\"]:\n",
    "    x_train_vals.append(sample[0].tolist())\n",
    "    \n",
    "x_test_vals = []\n",
    "for sample in x_test_context[\"embeddings\"]:\n",
    "    x_test_vals.append(sample[0].tolist())\n",
    "\n",
    "x_train_df = pd.DataFrame({'embeddings':x_train_vals})\n",
    "x_test_df = pd.DataFrame({'embeddings':x_test_vals})\n",
    "\n",
    "def process_dataframes(data):\n",
    "    temp_concat = pd.concat([data, data.embeddings.apply(pd.Series)], axis=1)\n",
    "    temp_concat.drop(columns=['embeddings'], inplace = True)\n",
    "    return temp_concat.add_prefix('feat_')\n",
    "\n",
    "x_train_df = process_dataframes(x_train_df)\n",
    "x_test_df = process_dataframes(x_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8797ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "report, best_est = svm_classifier(x_train_df, x_test_df, y_train.values.ravel(), y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f77dcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, class_weight=&#x27;balanced&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7b8eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6250    0.6198    0.6224       121\n",
      "         1.0     0.6198    0.6250    0.6224       120\n",
      "\n",
      "    accuracy                         0.6224       241\n",
      "   macro avg     0.6224    0.6224    0.6224       241\n",
      "weighted avg     0.6224    0.6224    0.6224       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43dcda2",
   "metadata": {},
   "source": [
    "### Speaker Dependent and Context Dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cee7ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_759</th>\n",
       "      <th>feat_760</th>\n",
       "      <th>feat_761</th>\n",
       "      <th>feat_762</th>\n",
       "      <th>feat_763</th>\n",
       "      <th>feat_764</th>\n",
       "      <th>feat_765</th>\n",
       "      <th>feat_766</th>\n",
       "      <th>feat_767</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.260339</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.106586</td>\n",
       "      <td>-0.676144</td>\n",
       "      <td>-0.056974</td>\n",
       "      <td>-0.265580</td>\n",
       "      <td>0.284544</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.410756</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.252734</td>\n",
       "      <td>0.529407</td>\n",
       "      <td>0.184306</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.459916</td>\n",
       "      <td>-0.170638</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.134949</td>\n",
       "      <td>-0.114905</td>\n",
       "      <td>-0.102827</td>\n",
       "      <td>-0.633639</td>\n",
       "      <td>-0.098503</td>\n",
       "      <td>-0.320460</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>-0.390006</td>\n",
       "      <td>0.096913</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489561</td>\n",
       "      <td>0.117410</td>\n",
       "      <td>0.546330</td>\n",
       "      <td>-0.219387</td>\n",
       "      <td>-0.194568</td>\n",
       "      <td>-0.079066</td>\n",
       "      <td>-0.086963</td>\n",
       "      <td>0.178945</td>\n",
       "      <td>-0.227929</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.217401</td>\n",
       "      <td>-0.259364</td>\n",
       "      <td>-0.071771</td>\n",
       "      <td>-0.751696</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>-0.386390</td>\n",
       "      <td>-0.077681</td>\n",
       "      <td>-0.160109</td>\n",
       "      <td>0.353239</td>\n",
       "      <td>-0.230072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472851</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>0.513739</td>\n",
       "      <td>-0.061896</td>\n",
       "      <td>-0.079626</td>\n",
       "      <td>-0.160311</td>\n",
       "      <td>-0.244905</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>0.054380</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019844</td>\n",
       "      <td>-0.093364</td>\n",
       "      <td>-0.102180</td>\n",
       "      <td>-0.508913</td>\n",
       "      <td>-0.119105</td>\n",
       "      <td>-0.061720</td>\n",
       "      <td>0.341775</td>\n",
       "      <td>-0.056822</td>\n",
       "      <td>0.204588</td>\n",
       "      <td>-0.145091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267042</td>\n",
       "      <td>-0.150327</td>\n",
       "      <td>0.492823</td>\n",
       "      <td>0.250624</td>\n",
       "      <td>-0.015410</td>\n",
       "      <td>-0.195509</td>\n",
       "      <td>-0.097871</td>\n",
       "      <td>0.067725</td>\n",
       "      <td>-0.136071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.155321</td>\n",
       "      <td>-0.299884</td>\n",
       "      <td>-0.195379</td>\n",
       "      <td>-0.620971</td>\n",
       "      <td>-0.181744</td>\n",
       "      <td>-0.381488</td>\n",
       "      <td>-0.021245</td>\n",
       "      <td>-0.115612</td>\n",
       "      <td>0.400439</td>\n",
       "      <td>0.029108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163647</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>0.246408</td>\n",
       "      <td>0.059884</td>\n",
       "      <td>-0.110360</td>\n",
       "      <td>-0.226482</td>\n",
       "      <td>-0.082159</td>\n",
       "      <td>0.085994</td>\n",
       "      <td>-0.098782</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>-0.147050</td>\n",
       "      <td>0.103499</td>\n",
       "      <td>0.013003</td>\n",
       "      <td>-0.674521</td>\n",
       "      <td>0.067728</td>\n",
       "      <td>-0.110955</td>\n",
       "      <td>0.039080</td>\n",
       "      <td>-0.274449</td>\n",
       "      <td>0.460904</td>\n",
       "      <td>0.075730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437590</td>\n",
       "      <td>0.116509</td>\n",
       "      <td>0.451178</td>\n",
       "      <td>0.059624</td>\n",
       "      <td>-0.058985</td>\n",
       "      <td>-0.167596</td>\n",
       "      <td>-0.156237</td>\n",
       "      <td>-0.120912</td>\n",
       "      <td>0.068402</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.030477</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>-0.235825</td>\n",
       "      <td>-0.668431</td>\n",
       "      <td>-0.319798</td>\n",
       "      <td>-0.045076</td>\n",
       "      <td>0.159677</td>\n",
       "      <td>-0.008670</td>\n",
       "      <td>0.256615</td>\n",
       "      <td>-0.055519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477176</td>\n",
       "      <td>-0.029886</td>\n",
       "      <td>0.105006</td>\n",
       "      <td>-0.093603</td>\n",
       "      <td>0.252784</td>\n",
       "      <td>0.138410</td>\n",
       "      <td>0.120047</td>\n",
       "      <td>0.082827</td>\n",
       "      <td>-0.146047</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.098432</td>\n",
       "      <td>-0.297345</td>\n",
       "      <td>-0.181105</td>\n",
       "      <td>-0.639331</td>\n",
       "      <td>0.087709</td>\n",
       "      <td>-0.507514</td>\n",
       "      <td>0.399132</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.151426</td>\n",
       "      <td>-0.078753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470522</td>\n",
       "      <td>-0.272250</td>\n",
       "      <td>0.491799</td>\n",
       "      <td>-0.074762</td>\n",
       "      <td>-0.179157</td>\n",
       "      <td>-0.329647</td>\n",
       "      <td>0.054555</td>\n",
       "      <td>0.098914</td>\n",
       "      <td>-0.212182</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>-0.213635</td>\n",
       "      <td>-0.292421</td>\n",
       "      <td>-0.203788</td>\n",
       "      <td>-0.575084</td>\n",
       "      <td>-0.075586</td>\n",
       "      <td>-0.717352</td>\n",
       "      <td>-0.067712</td>\n",
       "      <td>-0.233745</td>\n",
       "      <td>0.238681</td>\n",
       "      <td>-0.169930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314694</td>\n",
       "      <td>-0.160910</td>\n",
       "      <td>0.544496</td>\n",
       "      <td>-0.108063</td>\n",
       "      <td>-0.175749</td>\n",
       "      <td>-0.270244</td>\n",
       "      <td>-0.258349</td>\n",
       "      <td>0.058116</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-0.103304</td>\n",
       "      <td>-0.097534</td>\n",
       "      <td>-0.139065</td>\n",
       "      <td>-0.594170</td>\n",
       "      <td>-0.167461</td>\n",
       "      <td>-0.320940</td>\n",
       "      <td>-0.012872</td>\n",
       "      <td>-0.132135</td>\n",
       "      <td>0.262658</td>\n",
       "      <td>-0.136576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443993</td>\n",
       "      <td>0.025790</td>\n",
       "      <td>0.526676</td>\n",
       "      <td>-0.058676</td>\n",
       "      <td>-0.136962</td>\n",
       "      <td>-0.210749</td>\n",
       "      <td>0.026142</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>-0.070237</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n",
       "0   -0.260339 -0.001590 -0.106586 -0.676144 -0.056974 -0.265580  0.284544   \n",
       "1   -0.134949 -0.114905 -0.102827 -0.633639 -0.098503 -0.320460  0.012300   \n",
       "2   -0.217401 -0.259364 -0.071771 -0.751696  0.072838 -0.386390 -0.077681   \n",
       "3    0.019844 -0.093364 -0.102180 -0.508913 -0.119105 -0.061720  0.341775   \n",
       "4   -0.155321 -0.299884 -0.195379 -0.620971 -0.181744 -0.381488 -0.021245   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "956 -0.147050  0.103499  0.013003 -0.674521  0.067728 -0.110955  0.039080   \n",
       "957  0.030477  0.020006 -0.235825 -0.668431 -0.319798 -0.045076  0.159677   \n",
       "958  0.098432 -0.297345 -0.181105 -0.639331  0.087709 -0.507514  0.399132   \n",
       "959 -0.213635 -0.292421 -0.203788 -0.575084 -0.075586 -0.717352 -0.067712   \n",
       "960 -0.103304 -0.097534 -0.139065 -0.594170 -0.167461 -0.320940 -0.012872   \n",
       "\n",
       "       feat_7    feat_8    feat_9  ...  feat_759  feat_760  feat_761  \\\n",
       "0    0.005275  0.410756  0.016236  ...  0.180100  0.252734  0.529407   \n",
       "1   -0.390006  0.096913  0.000132  ...  0.489561  0.117410  0.546330   \n",
       "2   -0.160109  0.353239 -0.230072  ...  0.472851  0.014619  0.513739   \n",
       "3   -0.056822  0.204588 -0.145091  ...  0.267042 -0.150327  0.492823   \n",
       "4   -0.115612  0.400439  0.029108  ...  0.163647  0.016251  0.246408   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "956 -0.274449  0.460904  0.075730  ...  0.437590  0.116509  0.451178   \n",
       "957 -0.008670  0.256615 -0.055519  ...  0.477176 -0.029886  0.105006   \n",
       "958  0.006550  0.151426 -0.078753  ...  0.470522 -0.272250  0.491799   \n",
       "959 -0.233745  0.238681 -0.169930  ...  0.314694 -0.160910  0.544496   \n",
       "960 -0.132135  0.262658 -0.136576  ...  0.443993  0.025790  0.526676   \n",
       "\n",
       "     feat_762  feat_763  feat_764  feat_765  feat_766  feat_767  speaker  \n",
       "0    0.184306 -0.137758 -0.459916 -0.170638  0.016497  0.009023       25  \n",
       "1   -0.219387 -0.194568 -0.079066 -0.086963  0.178945 -0.227929        1  \n",
       "2   -0.061896 -0.079626 -0.160311 -0.244905 -0.000189  0.054380       16  \n",
       "3    0.250624 -0.015410 -0.195509 -0.097871  0.067725 -0.136071        0  \n",
       "4    0.059884 -0.110360 -0.226482 -0.082159  0.085994 -0.098782        2  \n",
       "..        ...       ...       ...       ...       ...       ...      ...  \n",
       "956  0.059624 -0.058985 -0.167596 -0.156237 -0.120912  0.068402        7  \n",
       "957 -0.093603  0.252784  0.138410  0.120047  0.082827 -0.146047       24  \n",
       "958 -0.074762 -0.179157 -0.329647  0.054555  0.098914 -0.212182        3  \n",
       "959 -0.108063 -0.175749 -0.270244 -0.258349  0.058116 -0.152623       15  \n",
       "960 -0.058676 -0.136962 -0.210749  0.026142  0.002957 -0.070237       24  \n",
       "\n",
       "[961 rows x 769 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df[\"speaker\"] = x_train_speakers[\"speaker\"]\n",
    "x_test_df[\"speaker\"] = x_test_speakers[\"speaker\"]\n",
    "x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9446dfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, class_weight=&#x27;balanced&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report, best_est = svm_classifier(x_train_df, x_test_df, y_train.values.ravel(), y_test.values.ravel())\n",
    "best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fda38afc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6549    0.6116    0.6325       121\n",
      "         1.0     0.6328    0.6750    0.6532       120\n",
      "\n",
      "    accuracy                         0.6432       241\n",
      "   macro avg     0.6438    0.6433    0.6429       241\n",
      "weighted avg     0.6439    0.6432    0.6428       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb048f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
