{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5ea386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71e9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../data/scene_labels.csv\")\n",
    "test_labels = pd.read_csv(\"final_train_test/y_test_final.csv\")\n",
    "test_labels = test_labels.merge(labels, left_on='scene', right_on='SCENE', how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376de440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(context_audio_features, audio_features):\n",
    "    model_data = pd.DataFrame(columns=['context_audio_feature', 'audio_feature','sarcasm', 'speaker'])\n",
    "    for index, row in test_labels.iterrows():\n",
    "        audio_key = row[\"SCENE\"] + \"_u.wav\"\n",
    "        context_audio_key = row[\"SCENE\"] + \"_c.wav\"\n",
    "        model_data = model_data.append({\n",
    "                                    'scene' : row[\"SCENE\"],\n",
    "                                    'context_audio_feature': context_audio_features[context_audio_key],\n",
    "                                    'audio_feature': audio_features[audio_key],\n",
    "                                    'sarcasm' : row[\"Sarcasm\"],\n",
    "                                    'speaker' : row[\"SPEAKER\"]},\n",
    "                                  ignore_index=True)\n",
    "    return model_data\n",
    "\n",
    "def get_test_split(model_data):\n",
    "    model_data.loc[model_data['scene'].isin(list(test_labels[\"SCENE\"]))]\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd8b2a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_audio_feature</th>\n",
       "      <th>audio_feature</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>speaker</th>\n",
       "      <th>scene</th>\n",
       "      <th>speaker_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-464.8975524902344, -504.45113845098587, -46...</td>\n",
       "      <td>[[-623.8641967773438, -565.6373408390925, -632...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHANDLER</td>\n",
       "      <td>2_388</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-640.9610595703125, -503.1803544786241, -506...</td>\n",
       "      <td>[[-421.7781066894531, -454.1127905594675, -529...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>1_5058</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-308.763671875, -489.3131433603715, -457.306...</td>\n",
       "      <td>[[-785.21826171875, -522.0255177815756, -390.1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>1_S11E21_080</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-432.1380615234375, -560.211009058459, -419....</td>\n",
       "      <td>[[-537.4343872070312, -504.6135768890381, -602...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RAJ</td>\n",
       "      <td>1_S11E12_038</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-707.3914794921875, -705.6019348144531, -591...</td>\n",
       "      <td>[[-240.57118225097656, -309.30991155450994, -3...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>1_S11E01_337</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               context_audio_feature  \\\n",
       "0  [[-464.8975524902344, -504.45113845098587, -46...   \n",
       "1  [[-640.9610595703125, -503.1803544786241, -506...   \n",
       "2  [[-308.763671875, -489.3131433603715, -457.306...   \n",
       "3  [[-432.1380615234375, -560.211009058459, -419....   \n",
       "4  [[-707.3914794921875, -705.6019348144531, -591...   \n",
       "\n",
       "                                       audio_feature  sarcasm   speaker  \\\n",
       "0  [[-623.8641967773438, -565.6373408390925, -632...      0.0  CHANDLER   \n",
       "1  [[-421.7781066894531, -454.1127905594675, -529...      1.0   SHELDON   \n",
       "2  [[-785.21826171875, -522.0255177815756, -390.1...      1.0    HOWARD   \n",
       "3  [[-537.4343872070312, -504.6135768890381, -602...      1.0       RAJ   \n",
       "4  [[-240.57118225097656, -309.30991155450994, -3...      0.0     PENNY   \n",
       "\n",
       "          scene  speaker_encode  \n",
       "0         2_388               2  \n",
       "1        1_5058              21  \n",
       "2  1_S11E21_080               6  \n",
       "3  1_S11E12_038              18  \n",
       "4  1_S11E01_337              13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../audio_features/feat_dict_librosa_lld.pickle', 'rb') as f:\n",
    "    librosa_audio_features = pickle.load(f, encoding='latin1')\n",
    "with open('../audio_features/feat_dict_context_librosa_lld.pickle', 'rb') as f:\n",
    "    librosa_context_audio_features = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "model_data = get_model_data(librosa_context_audio_features, librosa_audio_features)\n",
    "le = preprocessing.LabelEncoder()\n",
    "model_data['speaker_encode'] = le.fit_transform(model_data['speaker'])\n",
    "model_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e16da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = get_test_split(model_data)\n",
    "test_data = test_data[[\"context_audio_feature\", \"audio_feature\", \"speaker_encode\", \"sarcasm\"]]\n",
    "\n",
    "fnn_test = test_data.copy()\n",
    "fnn_test.reset_index(drop=True, inplace = True)\n",
    "fnn_test['averaged_audio_feature'] = fnn_test.loc[:, 'audio_feature']\n",
    "fnn_test['averaged_context_audio_feature'] = fnn_test.loc[:, 'context_audio_feature']\n",
    "for index, row in fnn_test.iterrows():\n",
    "    audio = row['averaged_audio_feature']\n",
    "    fnn_test.at[index, \"averaged_audio_feature\"] = np.array([np.mean(audio, axis=1)])\n",
    "    context_audio = row['averaged_context_audio_feature']\n",
    "    fnn_test.at[index, \"averaged_context_audio_feature\"] = np.array([np.mean(context_audio, axis=1)])\n",
    "\n",
    "fnn_test[\"sarcasm\"] = fnn_test[\"sarcasm\"].astype('int').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a23bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNNTensorDataset(Dataset):\n",
    "    def __init__(self, dataframe, speaker):\n",
    "        self.data = dataframe\n",
    "        self.speaker = speaker\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.speaker:\n",
    "            features = self.data.loc[index, 'averaged_audio_feature']\n",
    "            ctxt_features = self.data.loc[index, 'averaged_context_audio_feature']\n",
    "            a=np.empty((1,1))\n",
    "            a.fill(self.data.loc[index, 'speaker_encode'])\n",
    "            final_features = np.hstack((ctxt_features, features, a))\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.from_numpy(final_features).float(), label\n",
    "        else:\n",
    "            features = self.data.loc[index, 'averaged_audio_feature']\n",
    "            ctxt_features = self.data.loc[index, 'averaged_context_audio_feature']\n",
    "            final_features = np.hstack((ctxt_features, features))\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.from_numpy(final_features).float(), label\n",
    "    \n",
    "    def __getindexlist__(self):\n",
    "        return list(self.data.index.values)\n",
    "\n",
    "desired_frames = 1\n",
    "desired_features = 690\n",
    "class FNNNetSD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNNNetSD, self).__init__()\n",
    "        hidden_1 = 100\n",
    "        hidden_2 = 10\n",
    "        self.fc1 = nn.Linear(desired_frames*(desired_features + desired_features + 1), hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, desired_frames*(desired_features + desired_features + 1))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "fnn_test_tensor = FNNTensorDataset(fnn_test[['averaged_context_audio_feature', 'averaged_audio_feature', 'speaker_encode', 'sarcasm']], True)\n",
    "test_loader = torch.utils.data.DataLoader(fnn_test_tensor, batch_size=fnn_test_tensor.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5b832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNNNetSD(\n",
      "  (fc1): Linear(in_features=1381, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model = FNNNetSD()\n",
    "print(model)\n",
    "audio_best_model = model.load_state_dict(torch.load(\"fnn_audio_best_model80.pt\"))\n",
    "print(audio_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a28f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fnn(fnn_model, dataloader):\n",
    "    prediction_list = []\n",
    "    actual_list = []\n",
    "    for data, target in dataloader:\n",
    "        outputs = fnn_model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        prediction_list.append(predicted.cpu())\n",
    "        actual_list.append(target)\n",
    "    return prediction_list, actual_list\n",
    "predictions, actuals = predict_fnn(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd8fa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "         1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "         0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "         1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "         1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "         1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "         1])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c3cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_predictions = pd.DataFrame(list(zip(test_labels['scene'].tolist(), predictions[0].tolist(), actuals[0].tolist())), columns = ['scene', 'audio_predictions', 'actuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7310d7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene</th>\n",
       "      <th>audio_predictions</th>\n",
       "      <th>actuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_388</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_5058</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_S11E21_080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_S11E12_038</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_S11E01_337</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1_2423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2_242</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2_168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2_270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1_S10E05_110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            scene  audio_predictions  actuals\n",
       "0           2_388                  1        0\n",
       "1          1_5058                  1        1\n",
       "2    1_S11E21_080                  1        1\n",
       "3    1_S11E12_038                  1        1\n",
       "4    1_S11E01_337                  1        0\n",
       "..            ...                ...      ...\n",
       "236        1_2423                  0        0\n",
       "237         2_242                  1        1\n",
       "238         2_168                  1        1\n",
       "239         2_270                  0        0\n",
       "240  1_S10E05_110                  1        0\n",
       "\n",
       "[241 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07f9ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_predictions.to_csv(\"audio_predictions.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
