{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5ea386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4fcf68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(\"../text_features/bert_embeddings/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8b2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../text_features/bert_embeddings/test_bert_embeddings_target_.pkl', 'rb') as f:\n",
    "    x_test = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "x_test_speakers = pd.read_csv(\"../text_features/bert_embeddings/test_data.csv\")\n",
    "\n",
    "test_labels = pd.read_csv(\"final_train_test/y_test_final.csv\")\n",
    "    \n",
    "x_test_vals = []\n",
    "for sample in x_test[\"embeddings\"]:\n",
    "    x_test_vals.append(sample[0].tolist())\n",
    "x_test_df = pd.DataFrame({'embeddings':x_test_vals})\n",
    "x_test_df[\"sarcasm\"] = y_test[\"sarcasm\"]\n",
    "x_test_df[\"sarcasm\"] = x_test_df[\"sarcasm\"].astype('int').to_numpy()\n",
    "x_test_df[\"speaker\"] = x_test_speakers[\"speaker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b134b981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_</th>\n",
       "      <th>target_context</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] Yeah, she couldn't live without the Chan...</td>\n",
       "      <td>[CLS] Yeah, she couldn't live without the Chan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] An entire dinner to talk about your rese...</td>\n",
       "      <td>[CLS] An entire dinner to talk about your rese...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] Is it your teen years? [SEP]</td>\n",
       "      <td>[CLS] Is it your teen years? No, there's somet...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] That's funny. I always thought Howard wa...</td>\n",
       "      <td>[CLS] That's funny. I always thought Howard wa...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] I'm sorry, what? [SEP]</td>\n",
       "      <td>[CLS] I'm sorry, what? You could have a baby, ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>[CLS] Provided he has already read and is fami...</td>\n",
       "      <td>[CLS] Provided he has already read and is fami...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>[CLS] Are you still enjoying your nap? [SEP]</td>\n",
       "      <td>[CLS] Are you still enjoying your nap? Hi Emma...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>[CLS] Did I wake you? [SEP]</td>\n",
       "      <td>[CLS] Did I wake you? Are you kidding me? Joey...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>[CLS] Hey. [SEP]</td>\n",
       "      <td>[CLS] Hey. I didn't know there were docks. Wen...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>[CLS] The only thing I hate more than you righ...</td>\n",
       "      <td>[CLS] The only thing I hate more than you righ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               target_  \\\n",
       "0    [CLS] Yeah, she couldn't live without the Chan...   \n",
       "1    [CLS] An entire dinner to talk about your rese...   \n",
       "2                   [CLS] Is it your teen years? [SEP]   \n",
       "3    [CLS] That's funny. I always thought Howard wa...   \n",
       "4                         [CLS] I'm sorry, what? [SEP]   \n",
       "..                                                 ...   \n",
       "236  [CLS] Provided he has already read and is fami...   \n",
       "237       [CLS] Are you still enjoying your nap? [SEP]   \n",
       "238                        [CLS] Did I wake you? [SEP]   \n",
       "239                                   [CLS] Hey. [SEP]   \n",
       "240  [CLS] The only thing I hate more than you righ...   \n",
       "\n",
       "                                        target_context  speaker  \n",
       "0    [CLS] Yeah, she couldn't live without the Chan...        2  \n",
       "1    [CLS] An entire dinner to talk about your rese...       25  \n",
       "2    [CLS] Is it your teen years? No, there's somet...        7  \n",
       "3    [CLS] That's funny. I always thought Howard wa...       21  \n",
       "4    [CLS] I'm sorry, what? You could have a baby, ...       15  \n",
       "..                                                 ...      ...  \n",
       "236  [CLS] Provided he has already read and is fami...       25  \n",
       "237  [CLS] Are you still enjoying your nap? Hi Emma...        2  \n",
       "238  [CLS] Did I wake you? Are you kidding me? Joey...        2  \n",
       "239  [CLS] Hey. I didn't know there were docks. Wen...        8  \n",
       "240  [CLS] The only thing I hate more than you righ...        1  \n",
       "\n",
       "[241 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f1fb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.05679185688495636, -0.35763344168663025, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.3534734845161438, -0.37012195587158203, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.4724458158016205, -0.40140026807785034, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.20552656054496765, -0.378557950258255, -0.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.17461548745632172, 0.03321833908557892, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>[-0.09152349829673767, -0.6926221251487732, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>[0.4652370810508728, -0.27492570877075195, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>[0.3032662570476532, -0.21665722131729126, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>[-0.3526242971420288, 0.08399864286184311, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>[0.16504926979541779, 0.2321460247039795, -0.2...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            embeddings  sarcasm  speaker\n",
       "0    [-0.05679185688495636, -0.35763344168663025, -...        0        2\n",
       "1    [0.3534734845161438, -0.37012195587158203, -0....        1       25\n",
       "2    [0.4724458158016205, -0.40140026807785034, -0....        1        7\n",
       "3    [0.20552656054496765, -0.378557950258255, -0.1...        1       21\n",
       "4    [0.17461548745632172, 0.03321833908557892, -0....        0       15\n",
       "..                                                 ...      ...      ...\n",
       "236  [-0.09152349829673767, -0.6926221251487732, -0...        0       25\n",
       "237  [0.4652370810508728, -0.27492570877075195, -0....        1        2\n",
       "238  [0.3032662570476532, -0.21665722131729126, -0....        1        2\n",
       "239  [-0.3526242971420288, 0.08399864286184311, -0....        0        8\n",
       "240  [0.16504926979541779, 0.2321460247039795, -0.2...        0        1\n",
       "\n",
       "[241 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47dc8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNNTensorDataset(Dataset):\n",
    "    def __init__(self, dataframe, speaker):\n",
    "        self.data = dataframe\n",
    "        self.speaker = speaker\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.speaker:\n",
    "            features = self.data.loc[index, 'embeddings']\n",
    "            features = np.array(features)\n",
    "            a=np.empty((1,1))\n",
    "            a.fill(self.data.loc[index, 'speaker'])\n",
    "            a = a.reshape((-1,))\n",
    "            final_features = np.hstack((features, a))\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.Tensor(final_features).float(), label\n",
    "        else:\n",
    "            features = self.data.loc[index, 'embeddings']\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.Tensor(features).float(), label\n",
    "    \n",
    "    def __getindexlist__(self):\n",
    "        return list(self.data.index.values)\n",
    "    \n",
    "class FNNNetSD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNNNetSD, self).__init__()\n",
    "        hidden_1 = 100\n",
    "        hidden_2 = 10\n",
    "        self.fc1 = nn.Linear(769, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 769)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "fnn_test_tensor = FNNTensorDataset(x_test_df[['embeddings', 'speaker', 'sarcasm']], True)\n",
    "test_loader = torch.utils.data.DataLoader(fnn_test_tensor, batch_size=fnn_test_tensor.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c903e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNNNetSD(\n",
      "  (fc1): Linear(in_features=769, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model = FNNNetSD()\n",
    "print(model)\n",
    "audio_best_model = model.load_state_dict(torch.load(\"fnn_lexical_best_model20.pt\"))\n",
    "print(audio_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a28f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fnn(fnn_model, dataloader):\n",
    "    prediction_list = []\n",
    "    actual_list = []\n",
    "    for data, target in dataloader:\n",
    "        outputs = fnn_model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        prediction_list.append(predicted.cpu())\n",
    "        actual_list.append(target)\n",
    "    return prediction_list, actual_list\n",
    "predictions, actuals = predict_fnn(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd8fa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "         1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "         0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "         0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "         0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "         0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "         1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "         0])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c3cc2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (241, 1), indices imply (241, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lexical_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscene\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactuals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscene\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlexical_predictions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactuals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py:760\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    752\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    753\u001b[0m             arrays,\n\u001b[1;32m    754\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    758\u001b[0m         )\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 760\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    770\u001b[0m         {},\n\u001b[1;32m    771\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    775\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    345\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    346\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    347\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (241, 1), indices imply (241, 3)"
     ]
    }
   ],
   "source": [
    "lexical_predictions = pd.DataFrame(test_labels['scene'].tolist(), list(zip(predictions[0].tolist(), actuals[0].tolist())), columns = ['scene', 'lexical_predictions', 'actuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7310d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_predictions.to_csv(\"lexical_predictions.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
