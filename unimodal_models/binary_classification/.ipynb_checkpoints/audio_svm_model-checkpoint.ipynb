{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42e3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70375242",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../../data/scene_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776a1a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>KEY</th>\n",
       "      <th>SHOW</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Sarcasm_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_u</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_u</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>1_1001_u</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1003</td>\n",
       "      <td>1_1003_u</td>\n",
       "      <td>BBT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_10190</td>\n",
       "      <td>1_10190_u</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SCENE        KEY SHOW  Sarcasm Sarcasm_Type\n",
       "0  1_10004  1_10004_u  BBT      0.0         NONE\n",
       "1  1_10009  1_10009_u  BBT      0.0         NONE\n",
       "2   1_1001   1_1001_u  BBT      0.0         NONE\n",
       "3   1_1003   1_1003_u  BBT      1.0          PRO\n",
       "4  1_10190  1_10190_u  BBT      0.0         NONE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a947217",
   "metadata": {},
   "source": [
    "#### Perform mean, median, max, min and sum pooling on audio feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86800522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_mean_pool(audio) -> np.ndarray:\n",
    "        return np.array([np.mean(feature_vector, axis=1) for feature_vector in audio])\n",
    "    \n",
    "def get_audio_median_pool(audio) -> np.ndarray:\n",
    "        return np.array([np.median(feature_vector, axis=1) for feature_vector in audio])\n",
    "    \n",
    "def get_audio_max_pool(audio) -> np.ndarray:\n",
    "        return np.array([np.max(feature_vector, axis=1) for feature_vector in audio])\n",
    "\n",
    "def get_audio_min_pool(audio) -> np.ndarray:\n",
    "        return np.array([np.min(feature_vector, axis=1) for feature_vector in audio])\n",
    "\n",
    "def get_audio_sum_pool(audio) -> np.ndarray:\n",
    "        return np.array([np.sum(feature_vector, axis=1) for feature_vector in audio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9bd19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(audio_features):\n",
    "    model_data = pd.DataFrame(columns=['audio_feature','sarcasm','sarcasm_type'])\n",
    "    for index, row in labels.iterrows():\n",
    "        audio_key = row[\"SCENE\"] + \"_u.wav\"\n",
    "        model_data = model_data.append({'audio_feature': audio_features[audio_key],\n",
    "                                    'sarcasm' : row[\"Sarcasm\"],\n",
    "                                    'sarcasm_type' : row[\"Sarcasm_Type\"]},\n",
    "                                  ignore_index=True)\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac0ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(model_data, x_column, y_column, stratify_column):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        model_data[x_column],\n",
    "        model_data[y_column],\n",
    "        train_size=0.8, \n",
    "        test_size=0.2, \n",
    "        random_state=0, \n",
    "        shuffle=True,\n",
    "        stratify=model_data[stratify_column])\n",
    "    \n",
    "    print(\"Train: \",X_train.shape, Y_train.shape,\n",
    "      \"Test: \",(X_test.shape, Y_test.shape))\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def get_pooled_data(X_train, X_test, pool_type):\n",
    "    if pool_type == \"mean\":\n",
    "        X_train_mean = get_audio_mean_pool(X_train)\n",
    "        X_test_mean = get_audio_mean_pool(X_test)\n",
    "        return X_train_mean, X_test_mean\n",
    "    if pool_type == \"median\":\n",
    "        X_train_median = get_audio_median_pool(X_train)\n",
    "        X_test_median = get_audio_median_pool(X_test)\n",
    "        return X_train_median, X_test_median\n",
    "    if pool_type == \"max\":\n",
    "        X_train_max = get_audio_max_pool(X_train)\n",
    "        X_test_max = get_audio_max_pool(X_test)\n",
    "        return X_train_max, X_test_max\n",
    "    if pool_type == \"min\":\n",
    "        X_train_min = get_audio_min_pool(X_train)\n",
    "        X_test_min = get_audio_min_pool(X_test)\n",
    "        return X_train_min, X_test_min\n",
    "    if pool_type == \"sum\":\n",
    "        X_train_sum = get_audio_sum_pool(X_train)\n",
    "        X_test_sum = get_audio_sum_pool(X_test)\n",
    "        return X_train_sum, X_test_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b944a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(X_train, X_test, Y_train, Y_test):\n",
    "    svm_clf = svm.SVC(random_state=0, kernel = \"rbf\", gamma = \"scale\", class_weight = \"balanced\")\n",
    "    C = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gscv_clf = GridSearchCV(\n",
    "        estimator=svm_clf, \n",
    "        param_grid=dict(C=C),\n",
    "        n_jobs=-1, \n",
    "        cv = 10, \n",
    "        scoring = 'f1_macro', \n",
    "        refit = True)\n",
    "\n",
    "    gscv_clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = gscv_clf.predict(X_test)\n",
    "    report = classification_report(Y_test, Y_test_pred)\n",
    "    return report, gscv_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c3c666",
   "metadata": {},
   "source": [
    "### Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386872bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../audio_features/feat_dict_librosa_lld.pickle', 'rb') as f:\n",
    "    librosa_audio_features = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "model_data = get_model_data(librosa_audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d644d735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (961,) (961,) Test:  ((241,), (241,))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = get_train_test_split(model_data, 'audio_feature', 'sarcasm', 'sarcasm_type')\n",
    "X_train_mean, X_test_mean = get_pooled_data(X_train, X_test, \"mean\")\n",
    "X_train_median, X_test_median = get_pooled_data(X_train, X_test, \"median\")\n",
    "X_train_max, X_test_max = get_pooled_data(X_train, X_test, \"max\")\n",
    "X_train_min, X_test_min = get_pooled_data(X_train, X_test, \"min\")\n",
    "X_train_sum, X_test_sum = get_pooled_data(X_train, X_test, \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fe9c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_report, mean_best_est = svm_classifier(X_train_mean, X_test_mean, Y_train, Y_test)\n",
    "median_report, median_best_est = svm_classifier(X_train_median, X_test_median, Y_train, Y_test)\n",
    "max_report, max_best_est = svm_classifier(X_train_max, X_test_max, Y_train, Y_test)\n",
    "min_report, min_best_est = svm_classifier(X_train_min, X_test_min, Y_train, Y_test)\n",
    "sum_report, sum_best_est = svm_classifier(X_train_sum, X_test_sum, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2282c49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************mean report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.64      0.64       120\n",
      "         1.0       0.64      0.64      0.64       121\n",
      "\n",
      "    accuracy                           0.64       241\n",
      "   macro avg       0.64      0.64      0.64       241\n",
      "weighted avg       0.64      0.64      0.64       241\n",
      "\n",
      "SVC(C=10, class_weight='balanced', random_state=0)\n",
      "\n",
      "\n",
      "********************************median report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.61      0.63       120\n",
      "         1.0       0.64      0.68      0.66       121\n",
      "\n",
      "    accuracy                           0.64       241\n",
      "   macro avg       0.64      0.64      0.64       241\n",
      "weighted avg       0.64      0.64      0.64       241\n",
      "\n",
      "SVC(C=10, class_weight='balanced', random_state=0)\n",
      "\n",
      "\n",
      "********************************max report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.62      0.62       120\n",
      "         1.0       0.63      0.64      0.64       121\n",
      "\n",
      "    accuracy                           0.63       241\n",
      "   macro avg       0.63      0.63      0.63       241\n",
      "weighted avg       0.63      0.63      0.63       241\n",
      "\n",
      "SVC(C=10, class_weight='balanced', random_state=0)\n",
      "\n",
      "\n",
      "********************************min report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.66      0.63       120\n",
      "         1.0       0.63      0.59      0.61       121\n",
      "\n",
      "    accuracy                           0.62       241\n",
      "   macro avg       0.62      0.62      0.62       241\n",
      "weighted avg       0.62      0.62      0.62       241\n",
      "\n",
      "SVC(C=10, class_weight='balanced', random_state=0)\n",
      "\n",
      "\n",
      "********************************sum report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.62      0.63       120\n",
      "         1.0       0.63      0.64      0.64       121\n",
      "\n",
      "    accuracy                           0.63       241\n",
      "   macro avg       0.63      0.63      0.63       241\n",
      "weighted avg       0.63      0.63      0.63       241\n",
      "\n",
      "SVC(C=10, class_weight='balanced', random_state=0)\n"
     ]
    }
   ],
   "source": [
    "print(\"********************************mean report********************************\")\n",
    "print(mean_report)\n",
    "print(mean_best_est)\n",
    "print(\"\\n\")\n",
    "print(\"********************************median report********************************\")\n",
    "print(median_report)\n",
    "print(median_best_est)\n",
    "print(\"\\n\")\n",
    "print(\"********************************max report********************************\")\n",
    "print(max_report)\n",
    "print(max_best_est)\n",
    "print(\"\\n\")\n",
    "print(\"********************************min report********************************\")\n",
    "print(min_report)\n",
    "print(min_best_est)\n",
    "print(\"\\n\")\n",
    "print(\"********************************sum report********************************\")\n",
    "print(sum_report)\n",
    "print(sum_best_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35e235",
   "metadata": {},
   "source": [
    "### OpenSmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa8e5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../audio_features/feat_dict_opensmile_lld.pickle', 'rb') as f:\n",
    "    opensmile_audio_features = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "model_data = get_model_data(opensmile_audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e182e5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (961,) (961,) Test:  ((241,), (241,))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = get_train_test_split(model_data, 'audio_feature', 'sarcasm', 'sarcasm_type')\n",
    "X_train_mean, X_test_mean = get_pooled_data(X_train, X_test, \"mean\")\n",
    "X_train_median, X_test_median = get_pooled_data(X_train, X_test, \"median\")\n",
    "X_train_max, X_test_max = get_pooled_data(X_train, X_test, \"max\")\n",
    "X_train_min, X_test_min = get_pooled_data(X_train, X_test, \"min\")\n",
    "X_train_sum, X_test_sum = get_pooled_data(X_train, X_test, \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "133a4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_report, mean_best_est = svm_classifier(X_train_mean, X_test_mean, Y_train, Y_test)\n",
    "median_report, median_best_est = svm_classifier(X_train_median, X_test_median, Y_train, Y_test)\n",
    "max_report, max_best_est = svm_classifier(X_train_max, X_test_max, Y_train, Y_test)\n",
    "min_report, min_best_est = svm_classifier(X_train_min, X_test_min, Y_train, Y_test)\n",
    "sum_report, sum_best_est = svm_classifier(X_train_sum, X_test_sum, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86a00d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************mean report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.57      0.58       120\n",
      "         1.0       0.59      0.61      0.60       121\n",
      "\n",
      "    accuracy                           0.59       241\n",
      "   macro avg       0.59      0.59      0.59       241\n",
      "weighted avg       0.59      0.59      0.59       241\n",
      "\n",
      "SVC(C=10, class_weight='balanced', random_state=0)\n",
      "\n",
      "\n",
      "********************************median report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.39      0.49       120\n",
      "         1.0       0.57      0.79      0.66       121\n",
      "\n",
      "    accuracy                           0.59       241\n",
      "   macro avg       0.61      0.59      0.58       241\n",
      "weighted avg       0.61      0.59      0.58       241\n",
      "\n",
      "SVC(C=10, class_weight='balanced', random_state=0)\n",
      "\n",
      "\n",
      "********************************max report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.49      0.52       120\n",
      "         1.0       0.55      0.62      0.58       121\n",
      "\n",
      "    accuracy                           0.56       241\n",
      "   macro avg       0.56      0.56      0.55       241\n",
      "weighted avg       0.56      0.56      0.55       241\n",
      "\n",
      "SVC(C=1, class_weight='balanced', random_state=0)\n",
      "\n",
      "\n",
      "********************************min report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.43      0.52       120\n",
      "         1.0       0.57      0.76      0.65       121\n",
      "\n",
      "    accuracy                           0.60       241\n",
      "   macro avg       0.61      0.60      0.59       241\n",
      "weighted avg       0.61      0.60      0.59       241\n",
      "\n",
      "SVC(C=1, class_weight='balanced', random_state=0)\n",
      "\n",
      "\n",
      "********************************sum report********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.53      0.58       120\n",
      "         1.0       0.60      0.72      0.66       121\n",
      "\n",
      "    accuracy                           0.62       241\n",
      "   macro avg       0.63      0.62      0.62       241\n",
      "weighted avg       0.63      0.62      0.62       241\n",
      "\n",
      "SVC(C=10, class_weight='balanced', random_state=0)\n"
     ]
    }
   ],
   "source": [
    "print(\"********************************mean report********************************\")\n",
    "print(mean_report)\n",
    "print(mean_best_est)\n",
    "print(\"\\n\")\n",
    "print(\"********************************median report********************************\")\n",
    "print(median_report)\n",
    "print(median_best_est)\n",
    "print(\"\\n\")\n",
    "print(\"********************************max report********************************\")\n",
    "print(max_report)\n",
    "print(max_best_est)\n",
    "print(\"\\n\")\n",
    "print(\"********************************min report********************************\")\n",
    "print(min_report)\n",
    "print(min_best_est)\n",
    "print(\"\\n\")\n",
    "print(\"********************************sum report********************************\")\n",
    "print(sum_report)\n",
    "print(sum_best_est)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
