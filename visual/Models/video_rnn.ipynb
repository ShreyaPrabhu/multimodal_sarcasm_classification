{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "809d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "desired_frames = 1\n",
    "desired_features = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b3e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/data/scene_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17a8765",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>KEY</th>\n",
       "      <th>SPEAKER</th>\n",
       "      <th>SHOW</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Sarcasm_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_u</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_u</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>1_1001_u</td>\n",
       "      <td>RAJ</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1003</td>\n",
       "      <td>1_1003_u</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>BBT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_10190</td>\n",
       "      <td>1_10190_u</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SCENE        KEY  SPEAKER SHOW  Sarcasm Sarcasm_Type\n",
       "0  1_10004  1_10004_u  SHELDON  BBT      0.0         NONE\n",
       "1  1_10009  1_10009_u    PENNY  BBT      0.0         NONE\n",
       "2   1_1001   1_1001_u      RAJ  BBT      0.0         NONE\n",
       "3   1_1003   1_1003_u   HOWARD  BBT      1.0          PRO\n",
       "4  1_10190  1_10190_u  SHELDON  BBT      0.0         NONE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9904e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = list(pd.unique(labels[\"SCENE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88143cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41cdb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"/Users/yoshithaakunuri/Documents/CSCI535/Project/Final/data/features/utterances_final\"\n",
    "visual_features = {}\n",
    "for i in range(len(scenes)):\n",
    "    # Visual Features\n",
    "    try:\n",
    "        vf = np.load(os.path.join(parent_dir, \"resnet_pool5_\" + scenes[i] + \".npy\"))\n",
    "        #Global average pooling\n",
    "        vf_p = np.apply_over_axes(np.mean, vf, [2, 3]) \n",
    "        vf_p = np.reshape(vf_p, (vf_p.shape[0],2048))\n",
    "        if vf_p.shape[0] != 15:\n",
    "            vf_p = np.pad(vf_p, [(0, 15 - vf_p.shape[0]), (0, 0)], mode='constant')\n",
    "    except:\n",
    "        vf_p = np.zeros((15, 2048))\n",
    "    \n",
    "    visual_features[scenes[i]] = vf_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f80367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(video_features):\n",
    "    model_data = pd.DataFrame(columns=['video_feature','sarcasm','sarcasm_type', 'speaker'])\n",
    "    for index, row in labels.iterrows():\n",
    "        model_data = model_data.append({'video_feature': video_features[row[\"SCENE\"]],\n",
    "                                    'sarcasm' : row[\"Sarcasm\"],\n",
    "                                    'sarcasm_type' : row[\"Sarcasm_Type\"],\n",
    "                                    'speaker' : row[\"SPEAKER\"]},\n",
    "                                  ignore_index=True)\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c39e9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(model_data, x_columns, y_column, stratify_column):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        model_data[x_columns],\n",
    "        model_data[y_column],\n",
    "        train_size=0.8, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        shuffle=True,\n",
    "        stratify=model_data[stratify_column])\n",
    "    \n",
    "    print(\"Train: \",X_train.shape, Y_train.shape,\n",
    "      \"Test: \",(X_test.shape, Y_test.shape))\n",
    "    train_data = pd.merge(X_train, Y_train, left_index=True, right_index=True)\n",
    "    test_data = pd.merge(X_test, Y_test, left_index=True, right_index=True)\n",
    "    return train_data, test_data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d753e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTensorDataset(Dataset):\n",
    "    def __init__(self, dataframe, speaker):\n",
    "        self.data = dataframe\n",
    "        self.speaker = speaker\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.speaker:\n",
    "            features = self.data.loc[index, 'padded_video_feature']\n",
    "            a=np.empty((15,1))\n",
    "            a.fill(self.data.loc[index, 'speaker_encode'])\n",
    "            final_features = np.hstack((features, a))\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.from_numpy(final_features).float(), label\n",
    "        else:\n",
    "            features = self.data.loc[index, 'padded_video_feature']\n",
    "            label = self.data.loc[index, 'sarcasm']\n",
    "            return torch.from_numpy(features).float(), label\n",
    "    \n",
    "    def __getindexlist__(self):\n",
    "        return list(self.data.index.values)\n",
    "    \n",
    "class RNNetSD(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(RNNetSD, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = layers\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True, nonlinearity=\"relu\")\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = Variable(torch.zeros(self.layers, x.size(0), self.hidden_dim))\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = F.softmax(self.fc(out[:, -1, :]))\n",
    "        return out\n",
    "    \n",
    "class RNNetSID(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(RNNetSID, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = layers\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True, nonlinearity=\"relu\")\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = Variable(torch.zeros(self.layers, x.size(0), self.hidden_dim))\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = F.softmax(self.fc(out[:, -1, :]))\n",
    "        return out\n",
    "    \n",
    "def evaluateRNN(rnn, review, size):\n",
    "    output = rnn(review)\n",
    "    return output\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = torch.max(output,dim=1)\n",
    "    return top_i\n",
    "\n",
    "def test_accuracy(rnn, loader, size):\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    for data, target in loader:\n",
    "        output = evaluateRNN(rnn, data, size)\n",
    "        prediction_index = categoryFromOutput(output)\n",
    "        predictions = prediction_index.tolist()\n",
    "        actuals = target.tolist()\n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508b145f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_feature</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sarcasm_type</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.13835047, 0.2704592, 0.44648886, 0.1415337...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.46479157, 0.1813915, 0.22123067, 0.5245148...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.253619, 0.25664786, 0.6646118, 0.4821793, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>RAJ</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.55624646, 0.16990338, 0.62457716, 0.209021...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PRO</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.6140023, 0.4846397, 0.79425097, 0.13518682...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       video_feature  sarcasm sarcasm_type  \\\n",
       "0  [[0.13835047, 0.2704592, 0.44648886, 0.1415337...      0.0         NONE   \n",
       "1  [[0.46479157, 0.1813915, 0.22123067, 0.5245148...      0.0         NONE   \n",
       "2  [[0.253619, 0.25664786, 0.6646118, 0.4821793, ...      0.0         NONE   \n",
       "3  [[0.55624646, 0.16990338, 0.62457716, 0.209021...      1.0          PRO   \n",
       "4  [[0.6140023, 0.4846397, 0.79425097, 0.13518682...      0.0         NONE   \n",
       "\n",
       "   speaker  speaker_encode  \n",
       "0  SHELDON              25  \n",
       "1    PENNY              15  \n",
       "2      RAJ              21  \n",
       "3   HOWARD               7  \n",
       "4  SHELDON              25  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_data = get_model_data(visual_features)\n",
    "# Label Encode Speaker\n",
    "le = preprocessing.LabelEncoder()\n",
    "model_data['speaker_encode'] = le.fit_transform(model_data['speaker'])\n",
    "model_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d66053fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (961, 2) (961,) Test:  ((241, 2), (241,))\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_train_test_split(model_data, ['video_feature', 'speaker_encode'], 'sarcasm', 'sarcasm_type')\n",
    "rnn_train = train_data.copy()\n",
    "rnn_test = test_data.copy()\n",
    "rnn_train.reset_index(drop=True, inplace = True)\n",
    "rnn_test.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479135d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f6e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_length = 15\n",
    "\n",
    "rnn_train['padded_video_feature'] = rnn_train.loc[:, 'video_feature']\n",
    "rnn_test['padded_video_feature'] = rnn_test.loc[:, 'video_feature']\n",
    "\n",
    "rnn_train[\"sarcasm\"] = rnn_train[\"sarcasm\"].astype('int').to_numpy()\n",
    "rnn_test[\"sarcasm\"] = rnn_test[\"sarcasm\"].astype('int').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41fb73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM_sid = 2048\n",
    "EMBEDDING_DIM_sd = 2049\n",
    "HIDDEN_DIM = 20\n",
    "OUTPUT_DIM = 2\n",
    "layers = 2\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e6b92",
   "metadata": {},
   "source": [
    "### Speaker Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd381d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train_tensor = RNNTensorDataset(rnn_train[['padded_video_feature', 'sarcasm']], False)\n",
    "rnn_test_tensor = RNNTensorDataset(rnn_test[['padded_video_feature', 'sarcasm']], False)\n",
    "\n",
    "num_of_workers = 0\n",
    "batch_size = 44\n",
    "valid_size = 0.1\n",
    "\n",
    "train_indices = list(range(len(rnn_train_tensor)))\n",
    "np.random.shuffle(train_indices)\n",
    "\n",
    "test_indices = list(range(len(rnn_test_tensor)))\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    rnn_train_tensor, \n",
    "    batch_size=batch_size, \n",
    "    sampler=SubsetRandomSampler(train_indices)\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    rnn_test_tensor, \n",
    "    batch_size=batch_size, \n",
    "    sampler=SubsetRandomSampler(test_indices)\n",
    ")\n",
    "\n",
    "test_loader_epoch = torch.utils.data.DataLoader(\n",
    "    rnn_test_tensor, batch_size=rnn_test_tensor.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84b4fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNetSID(\n",
      "  (rnn): RNN(2048, 20, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNNetSID(EMBEDDING_DIM_sid, HIDDEN_DIM, OUTPUT_DIM, layers)\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c349baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       120\n",
      "           1     0.5021    1.0000    0.6685       121\n",
      "\n",
      "    accuracy                         0.5021       241\n",
      "   macro avg     0.2510    0.5000    0.3343       241\n",
      "weighted avg     0.2521    0.5021    0.3356       241\n",
      "\n",
      "Epoch: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6400    0.1333    0.2207       120\n",
      "           1     0.5185    0.9256    0.6647       121\n",
      "\n",
      "    accuracy                         0.5311       241\n",
      "   macro avg     0.5793    0.5295    0.4427       241\n",
      "weighted avg     0.5790    0.5311    0.4436       241\n",
      "\n",
      "Epoch: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6812    0.3917    0.4974       120\n",
      "           1     0.5756    0.8182    0.6758       121\n",
      "\n",
      "    accuracy                         0.6058       241\n",
      "   macro avg     0.6284    0.6049    0.5866       241\n",
      "weighted avg     0.6282    0.6058    0.5869       241\n",
      "\n",
      "Epoch: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6812    0.3917    0.4974       120\n",
      "           1     0.5756    0.8182    0.6758       121\n",
      "\n",
      "    accuracy                         0.6058       241\n",
      "   macro avg     0.6284    0.6049    0.5866       241\n",
      "weighted avg     0.6282    0.6058    0.5869       241\n",
      "\n",
      "Epoch: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5948    0.7583    0.6667       120\n",
      "           1     0.6705    0.4876    0.5646       121\n",
      "\n",
      "    accuracy                         0.6224       241\n",
      "   macro avg     0.6326    0.6230    0.6156       241\n",
      "weighted avg     0.6328    0.6224    0.6154       241\n",
      "\n",
      "Epoch: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6812    0.3917    0.4974       120\n",
      "           1     0.5756    0.8182    0.6758       121\n",
      "\n",
      "    accuracy                         0.6058       241\n",
      "   macro avg     0.6284    0.6049    0.5866       241\n",
      "weighted avg     0.6282    0.6058    0.5869       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 101\n",
    "    \n",
    "test_min_loss = np.inf\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    torch.manual_seed(42)\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    rnn.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = rnn(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    rnn.eval()\n",
    "    for data, target in test_loader:\n",
    "        if data.shape[1] < 44:\n",
    "            continue\n",
    "        output = rnn(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    if(epoch%20 == 0):\n",
    "        print(\"Epoch: \" + str(epoch))\n",
    "        predictions, actuals = test_accuracy(rnn, test_loader_epoch, rnn_test_tensor.__len__())\n",
    "        print(classification_report(actuals, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879089b1",
   "metadata": {},
   "source": [
    "### Speaker Dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f972827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train_tensor = RNNTensorDataset(rnn_train[['padded_video_feature', 'speaker_encode','sarcasm']], True)\n",
    "rnn_test_tensor = RNNTensorDataset(rnn_test[['padded_video_feature', 'speaker_encode', 'sarcasm']], True)\n",
    "\n",
    "num_of_workers = 0\n",
    "batch_size = 44\n",
    "valid_size = 0.1\n",
    "\n",
    "train_indices = list(range(len(rnn_train_tensor)))\n",
    "np.random.shuffle(train_indices)\n",
    "\n",
    "test_indices = list(range(len(rnn_test_tensor)))\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    rnn_train_tensor, \n",
    "    batch_size=batch_size, \n",
    "    sampler=SubsetRandomSampler(train_indices)\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    rnn_test_tensor, \n",
    "    batch_size=batch_size, \n",
    "    sampler=SubsetRandomSampler(test_indices)\n",
    ")\n",
    "\n",
    "test_loader_epoch = torch.utils.data.DataLoader(\n",
    "    rnn_test_tensor, batch_size=rnn_test_tensor.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c36ed74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNetSD(\n",
      "  (rnn): RNN(2049, 20, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNNetSD(EMBEDDING_DIM_sd, HIDDEN_DIM, OUTPUT_DIM, layers)\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d915c1f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6203    0.8167    0.7050       120\n",
      "           1     0.7349    0.5041    0.5980       121\n",
      "\n",
      "    accuracy                         0.6598       241\n",
      "   macro avg     0.6776    0.6604    0.6515       241\n",
      "weighted avg     0.6778    0.6598    0.6513       241\n",
      "\n",
      "Epoch: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5901    0.7917    0.6762       120\n",
      "           1     0.6875    0.4545    0.5473       121\n",
      "\n",
      "    accuracy                         0.6224       241\n",
      "   macro avg     0.6388    0.6231    0.6117       241\n",
      "weighted avg     0.6390    0.6224    0.6114       241\n",
      "\n",
      "Epoch: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7041    0.5750    0.6330       120\n",
      "           1     0.6434    0.7603    0.6970       121\n",
      "\n",
      "    accuracy                         0.6680       241\n",
      "   macro avg     0.6737    0.6677    0.6650       241\n",
      "weighted avg     0.6736    0.6680    0.6651       241\n",
      "\n",
      "Epoch: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7071    0.5833    0.6393       120\n",
      "           1     0.6479    0.7603    0.6996       121\n",
      "\n",
      "    accuracy                         0.6722       241\n",
      "   macro avg     0.6775    0.6718    0.6694       241\n",
      "weighted avg     0.6774    0.6722    0.6696       241\n",
      "\n",
      "Epoch: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6857    0.6000    0.6400       120\n",
      "           1     0.6471    0.7273    0.6848       121\n",
      "\n",
      "    accuracy                         0.6639       241\n",
      "   macro avg     0.6664    0.6636    0.6624       241\n",
      "weighted avg     0.6663    0.6639    0.6625       241\n",
      "\n",
      "Epoch: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6915    0.5417    0.6075       120\n",
      "           1     0.6259    0.7603    0.6866       121\n",
      "\n",
      "    accuracy                         0.6515       241\n",
      "   macro avg     0.6587    0.6510    0.6470       241\n",
      "weighted avg     0.6585    0.6515    0.6472       241\n",
      "\n",
      "Epoch: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7041    0.5750    0.6330       120\n",
      "           1     0.6434    0.7603    0.6970       121\n",
      "\n",
      "    accuracy                         0.6680       241\n",
      "   macro avg     0.6737    0.6677    0.6650       241\n",
      "weighted avg     0.6736    0.6680    0.6651       241\n",
      "\n",
      "Epoch: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7071    0.5833    0.6393       120\n",
      "           1     0.6479    0.7603    0.6996       121\n",
      "\n",
      "    accuracy                         0.6722       241\n",
      "   macro avg     0.6775    0.6718    0.6694       241\n",
      "weighted avg     0.6774    0.6722    0.6696       241\n",
      "\n",
      "Epoch: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6857    0.6000    0.6400       120\n",
      "           1     0.6471    0.7273    0.6848       121\n",
      "\n",
      "    accuracy                         0.6639       241\n",
      "   macro avg     0.6664    0.6636    0.6624       241\n",
      "weighted avg     0.6663    0.6639    0.6625       241\n",
      "\n",
      "Epoch: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7041    0.5750    0.6330       120\n",
      "           1     0.6434    0.7603    0.6970       121\n",
      "\n",
      "    accuracy                         0.6680       241\n",
      "   macro avg     0.6737    0.6677    0.6650       241\n",
      "weighted avg     0.6736    0.6680    0.6651       241\n",
      "\n",
      "Epoch: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5818    0.8000    0.6737       120\n",
      "           1     0.6842    0.4298    0.5279       121\n",
      "\n",
      "    accuracy                         0.6141       241\n",
      "   macro avg     0.6330    0.6149    0.6008       241\n",
      "weighted avg     0.6332    0.6141    0.6005       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 101\n",
    "    \n",
    "test_min_loss = np.inf\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    torch.manual_seed(42)\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    rnn.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = rnn(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    rnn.eval()\n",
    "    for data, target in test_loader:\n",
    "        if data.shape[1] < 44:\n",
    "            continue\n",
    "        output = rnn(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    if(epoch%10 == 0):\n",
    "        print(\"Epoch: \" + str(epoch))\n",
    "        predictions, actuals = test_accuracy(rnn, test_loader_epoch, rnn_test_tensor.__len__())\n",
    "        print(classification_report(actuals, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4bb5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
